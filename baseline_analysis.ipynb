{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline analysis workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Import common python libraries\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "# Import from root_numpy library\n",
    "import root_numpy\n",
    "from root_numpy import root2array, rec2array\n",
    "\n",
    "# Import from root_pandas library\n",
    "from root_pandas import read_root\n",
    "\n",
    "# Import panda library\n",
    "from pandas.tools import plotting\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from pandas.core.index import Index\n",
    "import pandas.core.common as com\n",
    "\n",
    "# Import scipy\n",
    "import scipy\n",
    "from scipy.stats import ks_2samp\n",
    "import scipy as sp\n",
    "from scipy.stats import distributions\n",
    "\n",
    "# Import itertools\n",
    "import itertools\n",
    "from itertools import cycle\n",
    "\n",
    "# Import Jupyter\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Import scikit-learn\n",
    "import sklearn\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import (confusion_matrix, roc_auc_score, roc_curve, \n",
    "                             auc, average_precision_score, precision_score, \n",
    "                             brier_score_loss, recall_score, f1_score, log_loss, \n",
    "                             classification_report, precision_recall_curve)\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import feature_selection\n",
    "\n",
    "## Keras deep neural network library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.regularizers import l1, l2 #,WeightRegularizer\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "# Import imblearn\n",
    "import imblearn\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# python regular-expression\n",
    "import re\n",
    "\n",
    "# Sciki-kit learn graph \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Check the versions of libraries/packages\n",
    "print(\"Python version \" + sys.version)\n",
    "print(\"Sklearn version \" + sklearn.__version__)\n",
    "print(\"Root_numpy version \" + root_numpy.__version__)\n",
    "print(\"Numpy version \" + np.__version__)\n",
    "print(\"Scipy version \" + scipy.__version__)\n",
    "print(\"Pandas version \" + pd.__version__)\n",
    "print(\"Matplotlib version \" + matplotlib.__version__)\n",
    "print(\"Seaborn version \" + sns.__version__)\n",
    "print(\"Imblance version \" +imblearn.__version__)\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Specifying which nodes should be run interactively\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Data loading function\n",
    "\n",
    "def load(sig_filename, bkg_filename, category, features):\n",
    "    \"\"\"load fucntion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sig_filename : array, shape = [n_samples]\n",
    "            true class, intergers in [0, n_classes - 1)\n",
    "    bkg_filename : array, shape = [n_samples, n_classes]\n",
    "    category: string\n",
    "    features: array, shape = [n_features]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pandas.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Read in ROOT file and produce panda dataframes\n",
    "    signal = read_root([sig_filename], category, columns=features)\n",
    "    signal['y']= 1 # add target column for signal\n",
    "\n",
    "    background = read_root([bkg_filename], category, columns=features)\n",
    "    background['y']= 0 # add target column for background\n",
    "\n",
    "    data = pd.concat([signal, background])\n",
    "    \n",
    "    return data                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Load input data files\n",
    "\n",
    "# Feature names\n",
    "branch_names = \"\"\"mass_tag_tag_min_deltaR,median_mass_jet_jet,\n",
    "    maxDeltaEta_tag_tag,mass_higgsLikeDijet,HT_tags,\n",
    "    btagDiscriminatorAverage_tagged,mass_jet_tag_min_deltaR,\n",
    "    mass_jet_jet_min_deltaR,mass_tag_tag_max_mass,maxDeltaEta_jet_jet,\n",
    "    centrality_jets_leps,centrality_tags,globalTimesEventWeight\"\"\".split(\",\")\n",
    "\n",
    "features = [c.strip() for c in branch_names]\n",
    "features = (b.replace(\" \", \"_\") for b in features)\n",
    "features = list(b.replace(\"-\", \"_\") for b in features)\n",
    "\n",
    "# Load dataset\n",
    "signal_sample = \"combined/signalMC.root\"\n",
    "background_sample = \"combined/backgroundMC.root\"\n",
    "tree_category = \"event_mvaVariables_step7_cate4\"\n",
    "\n",
    "data = load(signal_sample, background_sample, tree_category, features)\n",
    "\n",
    "print \"Total number of events: {}\\nNumber of features: {}\".format(len(data.index), len(data.columns))\n",
    "\n",
    "# Store a copy for later use\n",
    "df_archived = data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Function to extract class label counts and percentage\n",
    "\n",
    "def class_info(classes):\n",
    "    # Store the number of signal and background events\n",
    "    class_count = {}\n",
    "    counts = Counter(classes)\n",
    "    total = sum(counts.values())\n",
    "\n",
    "    for cls in counts.keys():\n",
    "        class_count[class_label[cls]] = counts[cls]\n",
    "        print(\"%10s: %7d  =  % 5.1f%%\" % (class_label[cls], counts[cls], float(counts[cls])/float((total))*100.0))\n",
    "\n",
    "    return (class_count[\"signal\"], class_count[\"background\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Determine class label counts and percentages\n",
    "\n",
    "class_label = {0.0: \"background\", 1.0: \"signal\"}\n",
    "class_info(data.y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Create features dataframe and target array\n",
    "\n",
    "df_X = data.drop(\"y\", axis=1, inplace=False)\n",
    "df_y = data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print \"background: \", sum(df_X[\"globalTimesEventWeight\"][df_y<0.5]), sum(df_X[\"globalTimesEventWeight\"][df_y<0.5])/(sum(df_X[\"globalTimesEventWeight\"][df_y<0.5])+sum(df_X[\"globalTimesEventWeight\"][df_y>0.5]))*100,\"%\"\n",
    "print \"signal: \", sum(df_X[\"globalTimesEventWeight\"][df_y>0.5]), sum(df_X[\"globalTimesEventWeight\"][df_y>0.5])/(sum(df_X[\"globalTimesEventWeight\"][df_y>0.5])+sum(df_X[\"globalTimesEventWeight\"][df_y<0.5]))*100,\"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Print statistical summary of dataset\n",
    "\n",
    "#Set the display format to be scientific for ease of analysis\n",
    "pd.options.display.float_format = '{:,.3g}'.format\n",
    "\n",
    "# To print out all rows and columns to the terminal\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "print \"Head:\"\n",
    "data.head()\n",
    "\n",
    "print \"Describe:\"\n",
    "data.describe()\n",
    "\n",
    "print \"Describe based on signal or data:\"\n",
    "data.groupby('y').describe()\n",
    "\n",
    "print \"Information:\" \n",
    "data.info()\n",
    "\n",
    "print \"Signal weight average:\"\n",
    "print data.groupby([\"y\"])['globalTimesEventWeight'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature visualization: basic exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Plot signal and background distributions for some variables\n",
    "\n",
    "def signal_background(data1, data2, column=None, grid=True,\n",
    "                      xlabelsize=None, xrot=None, ylabelsize=None,\n",
    "                      yrot=None, ax=None, sharex=False,\n",
    "                      sharey=False, figsize=None,\n",
    "                      layout=None, bins=10, **kwds):\n",
    "    \"\"\"Draw histogram of the DataFrame's series comparing the distribution\n",
    "    in `data1` to `data2`.\n",
    "\n",
    "    data1: DataFrame\n",
    "    data2: DataFrame\n",
    "    column: string or sequence\n",
    "       If passed, will be used to limit data to a subset of columns\n",
    "    grid : boolean, default True\n",
    "       Whether to show axis grid lines\n",
    "    xlabelsize : int, default None\n",
    "       If specified changes the x-axis label size\n",
    "    xrot : float, default None\n",
    "       rotation of x axis labels\n",
    "    ylabelsize : int, default None\n",
    "       If specified changes the y-axis label size\n",
    "    yrot : float, default None\n",
    "       rotation of y axis labels\n",
    "    ax : matplotlib axes object, default None\n",
    "    sharex : bool, if True, the X axis will be shared amongst all subplots.\n",
    "    sharey : bool, if True, the Y axis will be shared amongst all subplots.\n",
    "    figsize : tuple\n",
    "       The size of the figure to create in inches by default\n",
    "    layout: (optional) a tuple (rows, columns) for the layout of the histograms\n",
    "    bins: integer, default 10\n",
    "       Number of histogram bins to be used\n",
    "    kwds : other plotting keyword arguments\n",
    "       To be passed to hist function\n",
    "    \"\"\"\n",
    "    manification=20\n",
    "    background_weight = data1[\"globalTimesEventWeight\"]\n",
    "    signal_weight = data2[\"globalTimesEventWeight\"]*manification\n",
    "\n",
    "    if \"alpha\" not in kwds:\n",
    "        kwds[\"alpha\"] = 0.5\n",
    "\n",
    "    w, h = (12, 8)\n",
    "    figsize = (w, h)\n",
    "\n",
    "    if column is not None:\n",
    "        if not isinstance(column, (list, np.ndarray, Index)):\n",
    "            column = [column]\n",
    "        data1 = data1[column]\n",
    "        data2 = data2[column]\n",
    "\n",
    "    data1 = data1._get_numeric_data()\n",
    "    data2 = data2._get_numeric_data()\n",
    "    naxes = len(data1.columns)\n",
    "\n",
    "\n",
    "    fig, axes = plotting._subplots(naxes=naxes,\n",
    "                                   ax=ax, \n",
    "                                   squeeze=False,\n",
    "                                   sharex=sharex,\n",
    "                                   sharey=sharey,\n",
    "                                   figsize=figsize,\n",
    "                                   layout=layout)\n",
    "    xs = plotting._flatten(axes)\n",
    "\n",
    "    for i, col in enumerate(com._try_sort(data1.columns)):\n",
    "        ax = xs[i]\n",
    "        low = min(data1[col].min(), data2[col].min())\n",
    "        high = max(data1[col].max(), data2[col].max())\n",
    "        ax.hist(data1[col].dropna().values, weights=background_weight, \n",
    "                bins=bins, histtype='stepfilled', range=(low,high), **kwds)\n",
    "        ax.hist(data2[col].dropna().values, weights=signal_weight,\n",
    "                bins=bins, histtype='stepfilled', range=(low,high), **kwds)\n",
    "        ax.set_title(col)\n",
    "        ax.legend(['background', 'signal (%s)'% (manification)], loc='best')\n",
    "        ax.set_facecolor('white')\n",
    "    \n",
    "        # Customize the major grid\n",
    "        ax.grid(which='major', linestyle='-', linewidth='0.2', color='gray')\n",
    "        ax.set_facecolor('white')\n",
    "    \n",
    "\n",
    "    plotting._set_ticks_props(axes, xlabelsize=xlabelsize, xrot=xrot,\n",
    "                             ylabelsize=ylabelsize, yrot=yrot)\n",
    "    fig.subplots_adjust(wspace=0.5, hspace=0.8)\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Plot feature distributions\n",
    "\n",
    "signal_background(data[data[\"y\"] < 0.5],\n",
    "                  data[data[\"y\"] > 0.5],\n",
    "                  column=features, bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data[\"globalTimesEventWeight\"][data.y>0].hist(bins=70)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "data[\"globalTimesEventWeight\"][data.y<1].hist(bins=70)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "    \n",
    "def ensure_dir(directory):\n",
    "    \"\"\"When directory is not present, create it.\n",
    "    Arguments: \n",
    "    directory: name of directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Linear correlation matrix\n",
    "\n",
    "def correlations(data, **kwds):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    https://www.kaggle.com/wiki/MultiClassLogLoss\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array, shape = [n_samples]\n",
    "            true class, intergers in [0, n_classes - 1)\n",
    "    kwds : array, shape = [n_samples, n_classes]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    \"\"\"To calculate pairwise correlation between features.\n",
    "    \n",
    "    Extra arguments are passed on to DataFrame.corr()\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select signal or background label for plot title\n",
    "    if (data[\"y\"] > 0.5).all(axis=0):\n",
    "        label = \"signal\"\n",
    "    elif (data[\"y\"] < 0.5).all(axis=0):\n",
    "        label = \"background\"\n",
    "    \n",
    "    # simply call df.corr() to get a table of\n",
    "    # correlation values if you do not need\n",
    "    # the fancy plotting\n",
    "    data = data.drop(\"y\", axis=1) \n",
    " \n",
    "    # Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "    labels = data.corr(**kwds).columns.values\n",
    "    \n",
    "    fig, ax1 = plt.subplots(ncols=1, figsize=(9,8))\n",
    "    \n",
    "    opts = {\"annot\" : True,\n",
    "            \"ax\" : ax1,\n",
    "            \"vmin\": 0, \"vmax\": 1*100,\n",
    "            \"annot_kws\" : {\"size\": 8}, \n",
    "            \"cmap\": plt.get_cmap(\"Blues\", 20),\n",
    "            }\n",
    "    \n",
    "    ax1.set_title(\"Correlations: \" + label)\n",
    "\n",
    "    sns.heatmap(data.corr(method=\"spearman\").iloc[::-1]*100, **opts) \n",
    "    \n",
    "    plt.yticks(rotation=0)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    for ax in (ax1,):\n",
    "        # shift location of ticks to center of the bins\n",
    "        ax.set_xticks(np.arange(len(labels))+0.5, minor=False)\n",
    "        ax.set_yticks(np.arange(len(labels))+0.5, minor=False)\n",
    "        ax.set_xticklabels(labels[::-1], minor=False, ha=\"right\", rotation=70)\n",
    "        ax.set_yticklabels(np.flipud(labels), minor=False)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #  checks if directory exists and if not creates it\n",
    "    dir = 'plots'\n",
    "    ensure_dir(dir)\n",
    "    fig.savefig(dir+'/'+label+'_correlation_{}_features.pdf'.format(len(data.columns)))\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Plot feature correlations (assumes linear correlations)\n",
    "\n",
    "# Remove the y column from the correlation matrix\n",
    "# after using it to select background and signal\n",
    "sig = data[data[\"y\"] > 0.5].drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "bg = data[data[\"y\"] < 0.5].drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "\n",
    "# Correlation Matrix\n",
    "correlations(sig)\n",
    "correlations(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Scatter Plot\n",
    "#%matplotlib inline\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "random.seed(a=seed)\n",
    "\n",
    "sample_weight = data[\"globalTimesEventWeight\"].values\n",
    "\n",
    "g = sns.PairGrid(data.drop([\"globalTimesEventWeight\"], axis=1),\n",
    "                 hue=\"y\", palette=\"GnBu_d\",\n",
    "                 hue_kws={\"marker\": [\"o\", \"s\"]})\n",
    "_=g.map_diag(plt.hist)\n",
    "_=g.map_offdiag(plt.scatter, s=sample_weight, alpha=0.7, edgecolor=\"white\")\n",
    "_=g.add_legend();\n",
    "\n",
    "\n",
    "xlabels,ylabels = [],[]\n",
    "\n",
    "for ax in g.axes[-1,:]:\n",
    "    xlabel = ax.xaxis.get_label_text()\n",
    "    xlabels.append(xlabel)\n",
    "for ax in g.axes[:,0]:\n",
    "    ylabel = ax.yaxis.get_label_text()\n",
    "    ylabels.append(ylabel)\n",
    "\n",
    "for i in range(len(xlabels)):\n",
    "    for j in range(len(ylabels)):\n",
    "        _=g.axes[j,i].xaxis.set_label_text(xlabels[i])\n",
    "        _=g.axes[j,i].yaxis.set_label_text(ylabels[j])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#_ = sns.pairplot(data.drop([\"globalTimesEventWeight\"], axis=1), size=2.5, hue=\"y\", #kind=\"reg\",\n",
    "#                 markers=[\"o\", \"s\"], plot_kws={ \"s\": sample_weight, \"alpha\":0.7 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Keras Deep Neural Network modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create network with Keras: Function to create model, \n",
    "# required for KerasClassifier (model architecture)\n",
    "\n",
    "def build_model(optimizer='rmsprop', init='glorot_uniform', dropout_rate=0.0,\n",
    "                     learn_rate=0.01, momentum=0):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_samples]\n",
    "            true class, intergers in [0, n_classes - 1)\n",
    "    y_pred : array, shape = [n_samples, n_classes]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "    \"\"\"\n",
    "    \n",
    "    # create model: create a simple multi-layer neural network for the problem.\n",
    "\n",
    "    # Note: initialization of the weights was chose as default to be \n",
    "    # randomly drawn from a uniform distribution (if normal then the distribution\n",
    "    # would have mean 0 and standard deviation 0.05 in keras)\n",
    "\n",
    "    # expected input data shape: (batch_size, timesteps, data_dim)\n",
    "    model = Sequential()\n",
    "    # Rectify Linear Unit (Relu) = relu, Exponential Linear Unit (Elu) =  elu\n",
    "    model.add(Dense(12, input_dim=12, init=init, activation='elu')) \n",
    "    # ReLu(x) = {0 for x <=0 else x for x > 0}\n",
    "    model.add(Dropout(dropout_rate))\n",
    "     # 8 neurons in the hidden layer and 12 in the visible layer \n",
    "    model.add(Dense(8, init=init, activation='elu')) # 8 neurons in the hidden layer \n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, init=init, activation='sigmoid')) # 1 neuron in the output layer\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    #model.fit(x_train, y_train, verbose=1, batch_size=100, nb_epoch=50,\n",
    "    #          show_accuracy=True,validation_data=(x_test, y_test))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Function to create kearas network model, \n",
    "# required for KerasClassifier (model architecture)\n",
    "\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform', neurons=12,\n",
    "                 dropout_rate=0.0, weight_constraint=0,\n",
    "                 activation='elu',\n",
    "                 lr=0.01, momentum=0):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_samples]\n",
    "            true class, intergers in [0, n_classes - 1)\n",
    "    y_pred : array, shape = [n_samples, n_classes]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "    \"\"\"\n",
    "    \n",
    "    # Note: initialization of the weights was chose as default to be \n",
    "    # randomly drawn from a uniform distribution (if normal then the distribution\n",
    "    # would have mean 0 and standard deviation 0.05 in keras)\n",
    "\n",
    "    # expected input data shape: (batch_size, timesteps, data_dim)\n",
    "    \n",
    "    # create model: create a simple multi-layer neural network for the problem.\n",
    "    model = Sequential()\n",
    "    # Rectify Linear Unit (Relu) = relu, Exponential Linear Unit (Elu) =  elu\n",
    "    #model.add(Dense(12, input_dim=12, init=init, activation=activation))\n",
    "    model.add(Dense(neurons, input_dim=neurons, init=init, activation=activation))\n",
    "    #model.add(Dense(num_features, input_dim=len(num_features), init=init, activation='linear', \n",
    "    #W_constraint=maxnorm(weight_constraint)))\n",
    "\n",
    "    # ReLu(x) = {0 for x <=0 else x for x > 0}\n",
    "    model.add(Dropout(dropout_rate))\n",
    "     # 8 neurons in the hidden layer and 12 in the visible layer \n",
    "    model.add(Dense(8, init=init, activation=activation)) # 8 neurons in the hidden layer \n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, init=init, activation='sigmoid')) # 1 neuron in the output layer\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    #adam=keras.optimizers.Adam(lr=0.01)\n",
    "    #model.fit(x_train, y_train, verbose=1, batch_size=100, nb_epoch=200,\n",
    "    #          show_accuracy=True,validation_data=(x_test, y_test))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Plot AUC for ROC curve for several classifiers out-of-the-box\n",
    "\n",
    "# Set feature scaling type\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# create classifier for use in scikit-learn\n",
    "#model = KerasClassifier(build_fn=create_model, nb_epoch=50, batch_size=3, verbose=0)\n",
    "\n",
    "# prepare models: create a mapping of ML classifier name to algorithm\n",
    "pipe_classifiers = {\n",
    "    'KerasClassifier':  make_pipeline(scaler, KerasClassifier(build_fn=create_model, nb_epoch=50,\n",
    "                                                              batch_size=3, verbose=0)),\n",
    "    'SVC':  make_pipeline(scaler, SVC(probability=True, class_weight=\"balanced\")),\n",
    "    'LogisticRegression'    : make_pipeline(scaler, LogisticRegression(class_weight=\"balanced\")),\n",
    "    'AdaBoostClassifier'    : make_pipeline(None,   AdaBoostClassifier()),\n",
    "    'RandomForestClassifier': make_pipeline(None,   RandomForestClassifier(min_samples_leaf=10)),\n",
    "    'DecisionTreeClassifier': make_pipeline(None,   DecisionTreeClassifier(min_samples_leaf=10,\n",
    "                                                                           class_weight=\"balanced\")),\n",
    "    'GradientBoostingClassifier': make_pipeline(None,   GradientBoostingClassifier(min_samples_leaf=10)),\n",
    "    'BaggingClassifier': make_pipeline(None,   BaggingClassifier(n_estimators=50, max_samples=100,\n",
    "                                                                 max_features=12)),\n",
    "    'ExtraTreesClassifier' :  make_pipeline(None, ExtraTreesClassifier(min_samples_leaf=10)),#,\n",
    "    #'LinearDiscriminantAnalysis':  make_pipeline(scaler, LinearDiscriminantAnalysis()),\n",
    "    #'KNeighborsClassifier':  make_pipeline(scaler, KNeighborsClassifier()),\n",
    "    #'GaussianNB' :  make_pipeline(scaler, GaussianNB()), \n",
    "    #'MLPClassifier':  make_pipeline(scaler, MLPClassifier()), \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Compute ROC curve and area under the curve\n",
    "\n",
    "def roc_plot(models, X, y, n_folds=3, sample_weight_flag=True):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    https://www.kaggle.com/wiki/MultiClassLogLoss\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models : dictionary, shape = [n_models]\n",
    "    X : DataFrame, shape = [n_samples, n_classes]\n",
    "    y : DataFrame, shape = [n_classes]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    roc : matplotlib plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Split data into a development and evaluation set\n",
    "    X_dev, X_eval, y_dev, y_eval = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Split development set into a train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, \n",
    "                                                        test_size=0.33, random_state=seed)\n",
    "\n",
    "    # Extract training and test weights from dataset\n",
    "    sample_weight_dev = X_dev[\"globalTimesEventWeight\"].values\n",
    "    sample_weight_train = X_train[\"globalTimesEventWeight\"].values\n",
    "    sample_weight_test = X_test[\"globalTimesEventWeight\"].values\n",
    "\n",
    "    X_train = X_train.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "    X_test = X_test.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "\n",
    "    # contains rates for ML classifiers\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "\n",
    "    # Customize the major grid\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.grid(which='major', linestyle='-', linewidth='0.2', color='gray')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Include random by chance 'luck' curve\n",
    "    plt.plot([1, 0], [0, 1], '--', color=(0.1, 0.1, 0.1), label='Luck')\n",
    "\n",
    "    # Loop through classifiers\n",
    "    for (name, model) in models.items():\n",
    "\n",
    "        print \"\\n\\x1b[1;31mBuilding model \"+name+\" ...\\x1b[0m\"\n",
    "        process = time.clock()\n",
    "        if sample_weight_flag:\n",
    "            model.fit(X_train, y_train, **{name.lower()+'__sample_weight': sample_weight_train})\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        print \"\\t%s fit time: %.3f\"%(name, time.clock()-process)\n",
    "\n",
    "        y_predicted = model.predict(X_test)\n",
    "\n",
    "        process = time.clock()\n",
    "\n",
    "        # Statistics summary report\n",
    "        print classification_report(y_test, y_predicted, \n",
    "                                    target_names=['signal', 'background'],\n",
    "                                    sample_weight=sample_weight_test)\n",
    "        print(\"\\tScore (i.e. accuracy) of test dataset: {:.5f}\"\n",
    "              .format(model.score(X_test, y_test, #sample_weight=sample_weight_test\n",
    "                                 )))\n",
    "\n",
    "        #scores = cross_val_score(model, \n",
    "        #                         X_dev.drop('globalTimesEventWeight', axis=1, inplace=False),\n",
    "        #                         y_dev, scoring=\"roc_auc\", cv=n_folds, n_jobs=1,#n_jobs=-1\n",
    "        #                         fit_params={name.lower()+'__sample_weight': sample_weight_dev})\n",
    "\n",
    "        #print \"\\tCross-validated AUC ROC score: %0.5f (+/- %0.5f)\"%(scores.mean(), scores.std())\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            # probability estimates of the positive class(as needed in the roc_curve function)\n",
    "            decisions = model.predict_proba(X_test)[:, 1]\n",
    "        else:  # use decision function\n",
    "            decisions = model.decision_function(X_test)\n",
    "\n",
    "        process = time.clock()\n",
    "        fpr[name], tpr[name], thresholds = roc_curve(y_test, decisions,\n",
    "                                                     sample_weight=sample_weight_test)\n",
    "\n",
    "        # Non-cross-validated AUROC\n",
    "        roc_auc[name] = auc(fpr[name], tpr[name])\n",
    "        print \"\\tAUC ROC score for %s: %.4f\"%(name, roc_auc[name])\n",
    "        print \"\\tAUC ROC time: \", time.clock()-process\n",
    "\n",
    "    # color choices: https://css-tricks.com/snippets/css/named-colors-and-hex-equivalents/\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', \n",
    "                    'green', 'yellow', 'SlateBlue', 'DarkSlateGrey',\n",
    "                    'CadetBlue', 'Chocolate', 'darkred', 'GoldenRod'])\n",
    "\n",
    "    for (name, model), color in zip(models.items(), colors):\n",
    "\n",
    "        signal_efficiecy = tpr[name] # true positive rate (tpr)\n",
    "        background_efficiecy = fpr[name] # false positive rate (fpr)\n",
    "        # NOTE: background rejection rate = 1 - background efficiency (i.e specicity)\n",
    "        background_rejection_rate = 1 - background_efficiecy\n",
    "\n",
    "        plt.plot(signal_efficiecy, background_rejection_rate, color=color, lw=2,\n",
    "                 label='%s (AUC = %0.3f)'%(name, roc_auc[name]))                 \n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Signal Efficiency (True Positive Rate)')\n",
    "    plt.ylabel('Background Rejection Rate (1- False Positive Rate)')\n",
    "    plt.title(\"Receiver operating characteristic ({} events)\".format(X.shape[0]))\n",
    "    leg = plt.legend(loc=\"lower left\", frameon=True, fancybox=True, fontsize=10) # loc='best'\n",
    "    leg.get_frame().set_edgecolor('w')\n",
    "    frame = leg.get_frame()\n",
    "    frame.set_facecolor('White')\n",
    "\n",
    "    return plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Assessing the various classifiers performance\n",
    "\n",
    "roc_plot(pipe_classifiers, df_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Define precision-recall curve\n",
    "\n",
    "def plot_PR_curve(classifier, X, y, n_folds=5):\n",
    "    \"\"\"\n",
    "    Plot a basic precision/recall curve.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert negative weights to 1.0 (or else average_precision_score crashes)\n",
    "    X[\"globalTimesEventWeight\"] = X[\"globalTimesEventWeight\"].map(lambda x: 1.0 if x < 0.0 else x)\n",
    "    signal_sample_weight = X[\"globalTimesEventWeight\"][y>0.5].values\n",
    "    background_sample_weight = X[\"globalTimesEventWeight\"][y<0.5].values\n",
    "\n",
    "    # Customize the major grid\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.grid(which='major', linestyle='-', linewidth='0.2', color='gray')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Calculate the random luck for PR \n",
    "    # (above the constant line is a classifier that is well modeled)\n",
    "    signal_count = sum(signal_sample_weight*y[y>0.5])\n",
    "    background_count = sum(background_sample_weight*np.ones(len(y[y<0.5])))\n",
    "    ratio = float(signal_count)/float(signal_count + background_count)\n",
    "\n",
    "    # store average precision calculation\n",
    "    avg_scores = []\n",
    "\n",
    "    # Loop through classifiers\n",
    "    for (name, model) in classifier.items():\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "        for train, test in skf.split(X, y):\n",
    "\n",
    "            # Transform numpy array into panda dataframe to easier drop features\n",
    "            training_samples = pd.DataFrame(X.iloc[train], columns=features)\n",
    "            test_samples = pd.DataFrame(X.iloc[test], columns=features)\n",
    "\n",
    "            # Extract training and test sample weights from the dataset\n",
    "            sample_weight_train = training_samples[\"globalTimesEventWeight\"].values\n",
    "            sample_weight_test = test_samples[\"globalTimesEventWeight\"].values\n",
    "\n",
    "            # Drop event/sample weight feature\n",
    "            training_samples = training_samples.drop('globalTimesEventWeight',\n",
    "                                                     axis=1, inplace=False)\n",
    "            test_samples = test_samples.drop('globalTimesEventWeight',\n",
    "                                             axis=1, inplace=False)\n",
    "\n",
    "            model.fit(training_samples, y[train],\n",
    "                      **{name.lower()+'__sample_weight': sample_weight_train})   \n",
    "\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                probas_ = model.predict_proba(test_samples)[:, 1]\n",
    "            else:  # use decision function\n",
    "                probas_ = model.decision_function(test_samples)\n",
    "\n",
    "            # Compute precision recall curve\n",
    "            precision, recall, thresholds = precision_recall_curve(y[test],\n",
    "                                                                   probas_, pos_label=1,\n",
    "                                                                   sample_weight=sample_weight_test)\n",
    "            # Area under the precision-recall curve (AUCPR)\n",
    "            sample_weight_test = np.ones(len(sample_weight_test))\n",
    "\n",
    "            average_precision = average_precision_score(y[test], probas_, \n",
    "                                                        sample_weight=sample_weight_test)\n",
    "            avg_scores.append(average_precision)\n",
    "\n",
    "        plt.plot(recall, precision, lw=1, \n",
    "                 label='{0} (auc = {1:0.2f})'.format(name,np.mean(avg_scores, axis=0)))\n",
    "\n",
    "    plt.plot([ratio,ratio], '--', color=(0.1, 0.1, 0.1), \n",
    "             label='Luck (auc = {0:0.2f})'.format(ratio))\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-recall curve')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "# Plot precision-recall curve for several classifiers out-of-the-box\n",
    "\n",
    "plot_PR_curve(pipe_classifiers, df_X, df_y, n_folds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Overfitting evaluation\n",
    "\n",
    "### The Kolmogorov-Smirnov statistic\n",
    "\n",
    "We perform a two-sided asymptotic Kolmogorov-Smirnov test in which the null hypothesis stipulates that two independent samples are drawn from the same continuous parent distribution. If the K-S statistic is small or the p-value is high, then we cannot reject the hypothesis that the distributions of the two samples are the same. \n",
    "\n",
    "${\\displaystyle D_{n, n'}>c(\\alpha ){\\sqrt {\\frac {n + n'}{n \\cdot n'}}}}$, Where $n$ and $n'$ are the sizes of two samples, respectively, and\n",
    "\n",
    "${\\displaystyle c\\left(\\alpha \\right)={\\sqrt {-{\\frac {1}{2}}\\ln \\left({\\frac {\\alpha }{2}}\\right)}}}$\n",
    "\n",
    "We reject the null hypothesis at the 95% level hence $\\alpha=0.05$ corresponding to $c(0.05) = 1.36$.\n",
    "\n",
    "For signal distributions,\n",
    "\n",
    "${\\displaystyle D_{n_s, n'_s}>c(\\alpha ){\\sqrt {\\frac {n_s + n'_s}{n_s \\cdot n'_s}}}}$, Where $n_s$ and $n'_s$ are the sizes of training and test signal samples, respectively.\n",
    "\n",
    "For background distributions,\n",
    "\n",
    "${\\displaystyle D_{n_b, n'_b}>c(\\alpha ){\\sqrt {\\frac {n_b + n'_b}{n_b \\cdot n'_b}}}}$, Where $n_b$ and $n'_b$ are the sizes of training and test background samples, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Source:\n",
    "#       - https://github.com/scipy/scipy/blob/v0.14.0/scipy/stats/stats.py#L3809\n",
    "#       - https://stackoverflow.com/questions/40044375/how-to-calculate-the-kolmogorov-smirnov-statistic-between-two-weighted-samples\n",
    "\n",
    "def ks_weighted_2samp(data1, data2, wei1, wei2, alpha = 0.05):\n",
    "    \"\"\"\n",
    "    Computes the Kolmogorov-Smirnov statistic on 2 samples.\n",
    "    This is a two-sided test for the null hypothesis that 2 independent samples\n",
    "    are drawn from the same continuous distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data1, data2 : sequence of 1-D ndarrays\n",
    "        two arrays of sample observations assumed to be drawn from a continuous\n",
    "        distribution, sample sizes can be different\n",
    "\n",
    "    wei1, wei2 : sequence of 1-D ndarrays\n",
    "        two arrays with corresponding sample weights \n",
    "\n",
    "    alpha : float\n",
    "        confidence level\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    D : float\n",
    "        KS statistic\n",
    "    p-value : float\n",
    "        two-tailed p-value\n",
    "    \"\"\"\n",
    "\n",
    "    data1, data2 = map(np.asarray, (data1, data2))\n",
    "\n",
    "    hist1, bin_edges1 = np.histogram(data1, weights=wei1)\n",
    "    n1 = sum(hist1)\n",
    "    hist2, bin_edges2 = np.histogram(data2, weights=wei2)\n",
    "    n2 = sum(hist2)\n",
    "\n",
    "    ix1 = np.argsort(data1)\n",
    "    ix2 = np.argsort(data2)\n",
    "\n",
    "    data1 = data1[ix1]\n",
    "    data2 = data2[ix2]\n",
    "\n",
    "    wei1 = wei1[ix1]\n",
    "    wei2 = wei2[ix2]\n",
    "\n",
    "    data_all = np.concatenate([data1,data2])\n",
    "\n",
    "    cwei1 = np.hstack([0.,np.cumsum(wei1)*1./sum(wei1)])\n",
    "    cwei2 = np.hstack([0.,np.cumsum(wei2)*1./sum(wei2)])\n",
    "\n",
    "    cdf1we = cwei1[[np.searchsorted(data1,data_all,side='right')]]\n",
    "    cdf2we = cwei2[[np.searchsorted(data2,data_all,side='right')]]\n",
    "\n",
    "    d = np.max(np.absolute(cdf1we - cdf2we))\n",
    "\n",
    "    # Note: d absolute not signed distance\n",
    "    en = np.sqrt(n1*n2/float(n1+n2))\n",
    "\n",
    "    try:\n",
    "        prob = distributions.kstwobign.sf((en + 0.12 + 0.11 / en) * d)\n",
    "    except:\n",
    "        prob = 1.0\n",
    "\n",
    "    c_alpha = (-0.5*np.log(alpha/2.))**(0.5)\n",
    "    k_alpha = c_alpha/en\n",
    "\n",
    "    print \"\\n==============================\"\n",
    "    print \"Summary Report:\"\n",
    "    print \"KS(data) value: \", d\n",
    "    print \"KS(null) value: \", k_alpha\n",
    "    \n",
    "    if d > k_alpha:\n",
    "        print \"KS test: \", True, \" (null-hypothesis rejected)\"\n",
    "    else:\n",
    "        print \"KS test: \", False, \" (null-hypothesis not rejected)\"\n",
    "\n",
    "    return d, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def compute_cdf(ordered_weights):\n",
    "    \"\"\"Computes cumulative distribution function (CDF) by ordered weights,\n",
    "    be sure that sum(ordered_weights) == 1.\n",
    "    Minor difference: using symmetrized version\n",
    "    F(x) = 1/2 (F(x-0) + F(x+0))\n",
    "    \"\"\"\n",
    "    return np.cumsum(ordered_weights) - 0.5 * ordered_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def ks_2samp_weighted(data1, data2, weights1, weights2):\n",
    "    \"\"\"Kolmogorov-Smirnov distance, almost the same as ks2samp from scipy.stats, but this version supports weights.\n",
    "    :param data1: array-like of shape [n_samples1]\n",
    "    :param data2: array-like of shape [n_samples2]\n",
    "    :param weights1: None or array-like of shape [n_samples1]\n",
    "    :param weights2: None or array-like of shape [n_samples2]\n",
    "    :return: float, Kolmogorov-Smirnov distance.\n",
    "    \"\"\"\n",
    "    x = np.unique(np.concatenate([data1, data2]))\n",
    "    \n",
    "    weights1 = weights1 / np.sum(weights1) * 1.\n",
    "    weights2 = weights2 / np.sum(weights2) * 1.\n",
    "    \n",
    "    inds1 = np.searchsorted(x, data1)\n",
    "    inds2 = np.searchsorted(x, data2)\n",
    "    \n",
    "    w1 = np.bincount(inds1, weights=weights1, minlength=len(x))\n",
    "    w2 = np.bincount(inds2, weights=weights2, minlength=len(x))\n",
    "    \n",
    "    F1 = compute_cdf(w1)\n",
    "    F2 = compute_cdf(w2)\n",
    "    \n",
    "    return np.max(np.abs(F1 - F2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Defined overfitting plot\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "#plt.style.use(['white_background'])\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "def compare_train_test(clf, X_in, y_in, bins=50):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_samples]\n",
    "            true class, intergers in [0, n_classes - 1)\n",
    "    y_pred : array, shape = [n_samples, n_classes]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "    \"\"\"\n",
    "\n",
    "    if hasattr(clf, \"steps\"):\n",
    "        name = clf.steps[1][1].__class__.__name__\n",
    "    else:\n",
    "        name = clf.__class__.__name__\n",
    "\n",
    "    # Split data into a development and evaluation set\n",
    "    X_dev, X_eval, y_dev, y_eval = train_test_split(X_in, y_in, \n",
    "                                                    test_size=0.33, random_state=42)\n",
    "    # Split development set into a train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, \n",
    "                                                       test_size=0.33, random_state=seed)\n",
    "\n",
    "    sample_weight_train = X_train[\"globalTimesEventWeight\"].values\n",
    "\n",
    "    # Extract signal and background weights for traning set\n",
    "    signal_sample_weight_train = X_train[\"globalTimesEventWeight\"][y_train>0.5].values\n",
    "    background_sample_weight_train = X_train[\"globalTimesEventWeight\"][y_train<0.5].values\n",
    "\n",
    "    signal_sample_weight_test = X_test[\"globalTimesEventWeight\"][y_test>0.5].values\n",
    "    background_sample_weight_test = X_test[\"globalTimesEventWeight\"][y_test<0.5].values\n",
    "\n",
    "    X_train = X_train.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "    X_test = X_test.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "\n",
    "    # use subplot to extract axis to add ks and p-value to plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Customize the major grid\n",
    "    ax.grid(which='major', linestyle='-', linewidth='0.2', color='gray')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    if name != \"CalibratedClassifierCV\":\n",
    "        clf.fit(X_train, y_train, **{name.lower()+'__sample_weight': sample_weight_train})\n",
    "    else:\n",
    "        clf.fit(X_train, y_train, **{'sample_weight': sample_weight_train})\n",
    "\n",
    "    if hasattr(clf,\"decision_function\"):\n",
    "        d = clf.decision_function(X_in.drop('globalTimesEventWeight', axis=1, inplace=False))\n",
    "        bin_edges_low_high = np.linspace(min(d), max(d), bins + 1)\n",
    "    else:\n",
    "        bin_edges_low_high = np.linspace(0., 1., bins + 1)\n",
    "\n",
    "    decisions = []\n",
    "    for X, y in ((X_train, y_train), (X_test, y_test)):\n",
    "\n",
    "        if hasattr(clf,\"decision_function\"): #hasattr(clf,\"predict_proba\")\n",
    "            label_name = \"Decision Function\"\n",
    "            d1 = clf.decision_function(X[y>0.5]).ravel()\n",
    "            d2 = clf.decision_function(X[y<0.5]).ravel()\n",
    "            d = clf.decision_function(X)\n",
    "        else:\n",
    "            label_name = \"Prediction Probability\"\n",
    "            d1 = clf.predict_proba(X[y>0.5])[:, 1]\n",
    "            d2 = clf.predict_proba(X[y<0.5])[:, 1]\n",
    "            #d1 = cross_val_predict(clf, X[y>0.5], y, cv=3, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "            #d2 = cross_val_predict(clf, X[y<0.5], y, cv=3, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "                                   \n",
    "            \n",
    "        decisions += [d1, d2]\n",
    "\n",
    "    width = np.diff(bin_edges_low_high)\n",
    "\n",
    "    # Training signal and background histograms\n",
    "    hist_sig_train, bin_edges = np.histogram(decisions[0], bins=bin_edges_low_high,\n",
    "                                             weights=signal_sample_weight_train)\n",
    "\n",
    "    hist_sig_train = hist_sig_train/sum(hist_sig_train)\n",
    "\n",
    "    plt.bar(bin_edges[:-1], hist_sig_train, width=width, color='r', alpha=0.5, \n",
    "            label='signal (train)')\n",
    "\n",
    "    hist_bkg_train, bin_edges = np.histogram(decisions[1], bins=bin_edges_low_high,\n",
    "                                             weights=background_sample_weight_train)\n",
    "\n",
    "    hist_bkg_train = hist_bkg_train/sum(hist_bkg_train)\n",
    "\n",
    "    plt.bar(bin_edges[:-1], hist_bkg_train, width=width, \n",
    "            color='steelblue', alpha=0.5, label='background (train)')\n",
    "\n",
    "\n",
    "    # Test signal and background histograms\n",
    "    hist_sig_test, bin_edges = np.histogram(decisions[2], bins=bin_edges_low_high,\n",
    "                                            weights=signal_sample_weight_test)\n",
    "\n",
    "    hist_sig_test = hist_sig_test/sum(hist_sig_test)\n",
    "    scale = len(decisions[2]) / sum(hist_sig_test)\n",
    "    err = np.sqrt(hist_sig_test * scale) / scale\n",
    "    center = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    plt.errorbar(center, hist_sig_test, yerr=err, fmt='o', c='r', label='signal (test)')\n",
    "\n",
    "    hist_bkg_test, bin_edges = np.histogram(decisions[3], bins=bin_edges_low_high,\n",
    "                                            weights=background_sample_weight_test)\n",
    "\n",
    "    hist_bkg_test = hist_bkg_test/sum(hist_bkg_test)\n",
    "    scale = len(decisions[3]) / sum(hist_bkg_test)\n",
    "    err = np.sqrt(hist_bkg_test * scale) / scale\n",
    "\n",
    "    plt.errorbar(center, hist_bkg_test, yerr=err, fmt='o', c='steelblue', #range=low_high,\n",
    "                 label='background (test)')\n",
    "\n",
    "    # Estimate ks-test and p-values as an indicator of overtraining of fit model\n",
    "    s_ks, s_pv = ks_weighted_2samp(decisions[0], decisions[2], \n",
    "                                   signal_sample_weight_train, signal_sample_weight_test)\n",
    "    b_ks, b_pv = ks_weighted_2samp(decisions[1], decisions[3], \n",
    "                                   background_sample_weight_train, background_sample_weight_test)  \n",
    "    \n",
    "    print \"[CC]\", ks_weighted_2samp(decisions[0], decisions[2], signal_sample_weight_train, signal_sample_weight_test)\n",
    "    \n",
    "    print \"[EC]\", ks_2samp_weighted(decisions[0], decisions[2], signal_sample_weight_train, signal_sample_weight_test)    \n",
    "    \n",
    "    ax.set_title(\"Classifier: %s\\nsignal (background) ks: %f (%f)\\n p-value: %f (%f)\" \n",
    "                 % (name, s_ks, b_ks, s_pv, b_pv))\n",
    "\n",
    "    plt.xlabel(label_name)\n",
    "    plt.ylabel(\"Arbitrary units\")\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    # for the minor ticks, use no labels; default NullFormatter\n",
    "    plt.tick_params(which='both', width=2)\n",
    "    plt.tick_params(which='major', length=7, color='gray')\n",
    "    plt.tick_params(which='minor', length=4, color='gray')\n",
    "    #minorLocator = MultipleLocator(5)\n",
    "    minorLocator = AutoMinorLocator()\n",
    "    ax.xaxis.set_minor_locator(minorLocator)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Overfitting evaluation\n",
    "bins=50\n",
    "# Uncalibrated model predictions\n",
    "model = pipe_classifiers[\"GradientBoostingClassifier\"]\n",
    "compare_train_test(model, df_X, df_y, bins=bins)\n",
    "\n",
    "# Calibrated with isotonic calibration\n",
    "model_isotonic = CalibratedClassifierCV(model, cv=5, method='sigmoid')\n",
    "compare_train_test(model_isotonic, df_X, df_y, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Overfitting evaluation\n",
    "bins=50\n",
    "# Uncalibrated model predictions\n",
    "model = pipe_classifiers[\"AdaBoostClassifier\"]\n",
    "compare_train_test(model, df_X, df_y, bins=bins)\n",
    "\n",
    "# Calibrated with isotonic calibration\n",
    "model_isotonic = CalibratedClassifierCV(model, cv=5, method='sigmoid')\n",
    "compare_train_test(model_isotonic, df_X, df_y, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Overfitting evaluation\n",
    "bins=25\n",
    "# Uncalibrated model predictions\n",
    "model = pipe_classifiers[\"SVC\"]\n",
    "compare_train_test(model, df_X, df_y, bins=bins)\n",
    "\n",
    "# Calibrated with isotonic calibration\n",
    "model_isotonic = CalibratedClassifierCV(model, cv=5, method='sigmoid')\n",
    "compare_train_test(model_isotonic, df_X, df_y, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Overfitting evaluation\n",
    "bins=50\n",
    "# Uncalibrated model predictions\n",
    "model = pipe_classifiers[\"RandomForestClassifier\"]\n",
    "compare_train_test(model, df_X, df_y, bins=bins)\n",
    "\n",
    "# Calibrated with isotonic calibration\n",
    "model_isotonic = CalibratedClassifierCV(model, cv=5, method='sigmoid')\n",
    "compare_train_test(model_isotonic, df_X, df_y, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Overfitting evaluation\n",
    "bins=50\n",
    "# Uncalibrated model predictions (sample_weight not implemented)\n",
    "model = pipe_classifiers[\"ExtraTreesClassifier\"]\n",
    "compare_train_test(model, df_X, df_y, bins=bins)\n",
    "\n",
    "# Calibrated with isotonic calibration\n",
    "model_isotonic = CalibratedClassifierCV(model, cv=5, method='sigmoid')\n",
    "compare_train_test(model_isotonic, df_X, df_y, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Overfitting evaluation\n",
    "bins=50\n",
    "# Uncalibrated model predictions (sample_weight not implemented)\n",
    "model = pipe_classifiers[\"BaggingClassifier\"]\n",
    "compare_train_test(model, df_X, df_y, bins=bins)\n",
    "\n",
    "# Calibrated with isotonic calibration\n",
    "model_isotonic = CalibratedClassifierCV(model, cv=5, method='sigmoid')\n",
    "compare_train_test(model_isotonic, df_X, df_y, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Overfitting evaluation\n",
    "\n",
    "# NOTE: Classsifier does not implemented sample_weight: \n",
    "#      - LinearDiscriminantAnalysis, KNeighborsClassifier, GaussianNB, DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Probability calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Calibration curve (reliability curve)\n",
    "\n",
    "def plot_calibration_curve(est, X, y, fig_index, n_bins=10):\n",
    "    \"\"\"Plot calibration curve for est w/o and with calibration. \"\"\"\n",
    "    \n",
    "    # Split data into a development and evaluation set\n",
    "    X_dev,X_eval, y_dev,y_eval = train_test_split(X, y,\n",
    "                                                  test_size=0.33, random_state=42)\n",
    "    # Split development set into a train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.33,\n",
    "                                                        random_state=seed)\n",
    "    # Extract sample weights\n",
    "    sample_weight_train = X_train[\"globalTimesEventWeight\"].values\n",
    "    sample_weight_test = X_test[\"globalTimesEventWeight\"].values\n",
    "    \n",
    "    X_train = X_train.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "    X_test = X_test.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "    \n",
    "    # Calibrated with isotonic calibration\n",
    "    isotonic = CalibratedClassifierCV(est, cv=2, method='isotonic')\n",
    "\n",
    "    # Calibrated with sigmoid calibration\n",
    "    sigmoid = CalibratedClassifierCV(est, cv=2, method='sigmoid')\n",
    "\n",
    "    fig = plt.figure(fig_index, figsize=(6, 6))\n",
    "    ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "    ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "    ax1.plot([0, 1], [0, 1], \"--\", label=\"Perfectly calibrated\")\n",
    "\n",
    "    #print type(est)\n",
    "    #print type(isotonic)  \n",
    "    #print type(sigmoid)\n",
    "    \n",
    "    for clf, name in [(est, est.steps[1][0]),\n",
    "                      (isotonic, est.steps[1][0] + '_Isotonic'),\n",
    "                      (sigmoid, est.steps[1][0] + '_Sigmoid')]: # Also called Platt Scaling\n",
    "  \n",
    "        #clf.fit(X_train, y_train, sample_weight\n",
    "        if  clf.__class__.__name__ == \"CalibratedClassifierCV\":\n",
    "            clf.fit(X_train,y_train, **{'sample_weight': sample_weight_train})\n",
    "        else:\n",
    "            clf.fit(X_train,y_train, \n",
    "                    **{clf.steps[1][1].__class__.__name__.lower()\n",
    "                       +'__sample_weight': sample_weight_train});\n",
    "            \n",
    "        y_pred = clf.predict(X_test);\n",
    "        \n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            prob_pos = clf.predict_proba(X_test)[:, 1]\n",
    "        else:  # use decision function\n",
    "            prob_pos = clf.decision_function(X_test);\n",
    "            prob_pos = (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "\n",
    "        clf_score = brier_score_loss(y_test, prob_pos, pos_label=y.max())\n",
    "        print(\"\\n\\x1b[1;31mclassifier %s:\\x1b[0m\" % name)\n",
    "        print(\"\\tBrier: %1.3f\" % (clf_score))\n",
    "        print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred))\n",
    "        print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred))\n",
    "        print(\"\\tF1: %1.3f\\n\" % f1_score(y_test, y_pred))\n",
    "\n",
    "        fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=10)\n",
    "\n",
    "        ax1.plot(mean_predicted_value, fraction_of_positives, \"o-\",\n",
    "                 label=\"%s (%1.3f)\" % (name, clf_score))\n",
    "\n",
    "        ax2.hist(prob_pos, range=(0, 1), bins=n_bins, label=name, weights=sample_weight_test,\n",
    "                 histtype=\"step\", lw=2)\n",
    "\n",
    "    ax1.set_ylabel(\"Fraction of positives\")\n",
    "    ax1.set_ylim([-0.05, 1.05])\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "    # Customize the major grid\n",
    "    ax1.grid(which='major', linestyle='-', linewidth='0.2', color='gray')\n",
    "    ax1.set_facecolor('white')\n",
    "    \n",
    "    ax2.set_xlabel(\"Mean predicted value\")\n",
    "    ax2.set_ylabel(\"Count\")\n",
    "    ax2.legend(loc=\"best\", ncol=1)\n",
    "    \n",
    "    # Customize the major grid\n",
    "    ax2.grid(which='major', linestyle='-', linewidth='0.2', color='gray')\n",
    "    ax2.set_facecolor('white')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Plot reliability curve (i.e. calibration curve)\n",
    "\n",
    "plot_calibration_curve(make_pipeline(None, SVC()), df_X, df_y, 2)\n",
    "plot_calibration_curve(pipe_classifiers[\"SVC\"],   df_X, df_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Plot reliability curve (i.e. calibration curve)\n",
    "\n",
    "plot_calibration_curve(make_pipeline(None, LogisticRegression()), df_X, df_y, 2)\n",
    "plot_calibration_curve(pipe_classifiers[\"LogisticRegression\"],   df_X, df_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Plot reliability curve (i.e. calibration curve)\n",
    "\n",
    "plot_calibration_curve(pipe_classifiers[\"AdaBoostClassifier\"],  df_X, df_y, 2)\n",
    "plot_calibration_curve(pipe_classifiers[\"GradientBoostingClassifier\"], df_X, df_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Plot reliability curve (i.e. calibration curve)\n",
    "\n",
    "#plot_calibration_curve(pipe_classifiers[\"DecisionTreeClassifier\"], df_X, df_y, 2) # problem with predict\n",
    "#plot_calibration_curve(pipe_classifiers[\"RandomForestClassifier\"],  df_X, df_y, 2) # problem with predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Plot reliability curve (i.e. calibration curve)\n",
    "\n",
    "#plot_calibration_curve(make_pipeline(None, GaussianNB()), df_X, df_y, 2)\n",
    "#plot_calibration_curve(pipe_classifiers[\"GaussianNB\"],   df_X, df_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Plot reliability curve (i.e. calibration curve)\n",
    "\n",
    "#plot_calibration_curve(make_pipeline(None, LinearDiscriminantAnalysis()), df_X, df_y, 2)\n",
    "#plot_calibration_curve(pipe_classifiers[\"LinearDiscriminantAnalysis\"],  df_X, df_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Plot reliability curve (i.e. calibration curve)\n",
    "\n",
    "#plot_calibration_curve(make_pipeline(None, KNeighborsClassifier()), df_X, df_y, 2)\n",
    "#plot_calibration_curve(pipe_classifiers[\"KNeighborsClassifier\"],  df_X, df_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Plot reliability curve (i.e. calibration curve)\n",
    "\n",
    "#plot_calibration_curve(make_pipeline(None, MLPClassifier()), df_X, df_y, 2)\n",
    "#plot_calibration_curve(pipe_classifiers[\"MLPClassifier\"],  df_X, df_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Confusion matrix plot\n",
    "\n",
    "def plot_confusion_matrix(clf, X, y, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    https://www.kaggle.com/wiki/MultiClassLogLoss\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_samples]\n",
    "            true class, intergers in [0, n_classes - 1)\n",
    "    y_pred : array, shape = [n_samples, n_classes]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    # Split data into a development and evaluation set\n",
    "    X_dev,X_eval, y_dev,y_eval = train_test_split(X, y,\n",
    "                                              test_size=0.33, random_state=42)\n",
    "    # Split development set into a train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.33,\n",
    "                                                        random_state=seed)\n",
    "    \n",
    "    sample_weight = X_train[\"globalTimesEventWeight\"].values\n",
    "    \n",
    "    X_train = X_train.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "    X_test = X_test.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "    \n",
    "    classifier = clf.fit(X_train,y_train, \n",
    "                         **{clf.steps[1][1].__class__.__name__.lower()\n",
    "                            +'__sample_weight': sample_weight}) \n",
    "\n",
    "    \n",
    "    #classifier = clf.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap);\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    name = clf.steps[1][0]\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    " \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(False, which='both')\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Set envorinment\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "class_names = ['Background', 'Signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Generate confusion matrix plot\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "clf = pipe_classifiers[\"GradientBoostingClassifier\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names,\n",
    "                      title=\"Classifier: %s\\nConfusion matrix, without normalization\"%(\"Gradient-Boosting\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Generate confusion matrix plot\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "clf = pipe_classifiers[\"GradientBoostingClassifier\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names, normalize=True,\n",
    "                      title=\"Classifier: %s\\nNormalized confusion matrix\"%(\"Gradient-Boosting\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Generate confusion matrix plot\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "clf = pipe_classifiers[\"AdaBoostClassifier\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names,\n",
    "                      title=\"Classifier: %s\\nConfusion matrix, without normalization\"%(\"Adaptive-Boosting\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Generate confusion matrix plot\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "clf = pipe_classifiers[\"AdaBoostClassifier\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names, normalize=True,\n",
    "                      title=\"Classifier: %s\\nNormalized confusion matrix\"%(\"Adaptive-Boosting\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Generate confusion matrix plot\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "clf = pipe_classifiers[\"SVC\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names,\n",
    "                      title=\"Classifier: %s\\nConfusion matrix, without normalization\"%(\"Support Vector\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Generate confusion matrix plot\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "clf = pipe_classifiers[\"SVC\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names, normalize=True,\n",
    "                      title=\"Classifier: %s\\nNormalized confusion matrix\"%(\"Super Vector\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Plot non-normalized confusion matrix\n",
    "clf = pipe_classifiers[\"LogisticRegression\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names,\n",
    "                      title=\"Classifier: %s\\nConfusion matrix, without normalization\"%(\"Logistic Regression\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Generate confusion matrix plot\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "clf = pipe_classifiers[\"LogisticRegression\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names, normalize=True,\n",
    "                      title=\"Classifier: %s\\nNormalized confusion matrix\"%(\"Logistic Regression\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Generate confusion matrix plot\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "clf = pipe_classifiers[\"GradientBoostingClassifier\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names,\n",
    "                      title=\"Classifier: %s\\nConfusion matrix, without normalization\"%(\"Random Forest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Generate confusion matrix plot\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "clf = pipe_classifiers[\"GradientBoostingClassifier\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names, normalize=True,\n",
    "                      title=\"Classifier: %s\\nNormalized confusion matrix\"%(\"Random Forest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Generate confusion matrix plot\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "clf = pipe_classifiers[\"DecisionTreeClassifier\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names,\n",
    "                      title=\"Classifier: %s\\nConfusion matrix, without normalization\"%(\"Decision Tree\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Generate confusion matrix plot\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "clf = pipe_classifiers[\"DecisionTreeClassifier\"]\n",
    "plot_confusion_matrix(clf, df_X, df_y, classes=class_names, normalize=True,\n",
    "                      title=\"Classifier: %s\\nNormalized confusion matrix\"%(\"Decision Tree\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "#clf = pipe_classifiers[\"LinearDiscriminantAnalysis\"]\n",
    "#plot_confusion_matrix(clf, df_X, df_y, classes=class_names,\n",
    "#                      title=\"Classifier: %s\\nConfusion matrix, without normalization\"%(\"Linear Discriminant Analysis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "#clf = pipe_classifiers[\"LinearDiscriminantAnalysis\"]\n",
    "#plot_confusion_matrix(clf, df_X, df_y, classes=class_names, normalize=True,\n",
    "#                      title=\"Classifier: %s\\nNormalized confusion matrix\"%(\"Linear Discriminant Analysis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "#clf = pipe_classifiers[\"GaussianNB\"]\n",
    "#plot_confusion_matrix(clf, df_X, df_y, classes=class_names,\n",
    "#                      title=\"Classifier: %s\\nConfusion matrix, without normalization\"%(\"Guassian Naive Bayes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "#clf = pipe_classifiers[\"GaussianNB\"]\n",
    "#plot_confusion_matrix(clf, df_X, df_y, classes=class_names, normalize=True,\n",
    "#                      title=\"Classifier: %s\\nNormalized confusion matrix\"%(\"Gaussian Naive Bayes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "#clf = pipe_classifiers[\"KNeighborsClassifier\"]\n",
    "#plot_confusion_matrix(clf, df_X, df_y, classes=class_names,\n",
    "#                      title=\"Classifier: %s\\nConfusion matrix, without normalization\"%(\"K-Nearest Neighbor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "#clf = pipe_classifiers[\"KNeighborsClassifier\"]\n",
    "#plot_confusion_matrix(clf, df_X, df_y, classes=class_names, normalize=True,\n",
    "#                      title=\"Classifier: %s\\nNormalized confusion matrix\"%(\"K-Nearest Neighbor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Learning curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \n",
    "    \"\"\"\n",
    "    ========================\n",
    "    Plotting Learning Curves\n",
    "    ========================\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    #train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)    \n",
    "    train_sizes_abs, train_scores, test_scores = \\\n",
    "    learning_curve(estimator, X, y,\n",
    "                   train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                   cv=None, scoring=None,\n",
    "                   exploit_incremental_learning=False,\n",
    "                   n_jobs=1, pre_dispatch=\"all\", verbose=0)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time # FIXME: CURRENTLY CRASHES USED TO WORK\n",
    "## Plot learning curve\n",
    "\n",
    "title = \"Learning Curves (Gradient Boosting)\"\n",
    "\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.33, random_state=0)\n",
    "\n",
    "estimator = GradientBoostingClassifier()\n",
    "plot_learning_curve(estimator, title, df_X.drop('globalTimesEventWeight', axis=1, inplace=False), \n",
    "                    df_y, ylim=(0.4, 1.01), cv=cv, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def plot_curve():\n",
    "    # instantiate\n",
    "    lg = LinearRegression()\n",
    "\n",
    "    # fit\n",
    "    X = df_X.drop('globalTimesEventWeight', axis=1, inplace=False).values\n",
    "    y = df_y.values\n",
    "    lg.fit(X, y)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "        \n",
    "    x1 = np.linspace(0, 10, 8, endpoint=True) produces\n",
    "        8 evenly spaced points in the range 0 to 10\n",
    "    \"\"\"\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(lg, X, y, n_jobs=-1, cv=cv, \n",
    "                                                            train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"RandomForestClassifier\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, \n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, \n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()\n",
    "\n",
    "plot_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydot\n",
    "\n",
    "clf = ExtraTreeClassifier()\n",
    "\n",
    "dot_data = StringIO() \n",
    "tree.export_graphviz(clf, out_file=dot_data) \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "file_name = \"DT_ttH.pdf\"\n",
    "graph.write_pdf(file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
