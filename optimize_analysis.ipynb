{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DesyFellow/Library/Python/2.7/lib/python/site-packages/root_numpy/__init__.py:46: RuntimeWarning: numpy 1.12.1 is currently installed but you installed root_numpy against numpy 1.12.0. Please consider reinstalling root_numpy for this numpy version.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 12:39:47) \n",
      "[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)]\n",
      "Sklearn version 0.18.1\n",
      "Root_numpy version 4.7.2\n",
      "Numpy version 1.12.1\n",
      "Scipy version 0.18.1\n",
      "Pandas version 0.19.0+515.gd0a281f\n",
      "Matplotlib version 2.0.0\n",
      "Seaborn version 0.8.dev\n",
      "Imblance version 0.2.1\n",
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "## Import common python libraries\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "# Import from root_numpy library\n",
    "import root_numpy\n",
    "from root_numpy import root2array, rec2array\n",
    "\n",
    "# Import panda library\n",
    "from pandas.tools import plotting\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from pandas.core.index import Index\n",
    "import pandas.core.common as com\n",
    "\n",
    "# Import scipy\n",
    "import scipy\n",
    "from scipy.stats import ks_2samp\n",
    "import scipy as sp\n",
    "\n",
    "# Import itertools\n",
    "import itertools\n",
    "from itertools import cycle\n",
    "\n",
    "# Import Jupyter\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Import scikit-learn\n",
    "import sklearn\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import (confusion_matrix, roc_auc_score, roc_curve, \n",
    "                             auc, average_precision_score, precision_score, \n",
    "                             brier_score_loss, recall_score, f1_score, log_loss, \n",
    "                             classification_report, precision_recall_curve, accuracy_score)\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import feature_selection\n",
    "\n",
    "# Import imblearn\n",
    "import imblearn\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Optimize \n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "# python utilities\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# python regular-expression\n",
    "import re\n",
    "\n",
    "# Sciki-kit learn graph \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Check the versions of libraries/packages\n",
    "print(\"Python version \" + sys.version)\n",
    "print(\"Sklearn version \" + sklearn.__version__)\n",
    "print(\"Root_numpy version \" + root_numpy.__version__)\n",
    "print(\"Numpy version \" + np.__version__)\n",
    "print(\"Scipy version \" + scipy.__version__)\n",
    "print(\"Pandas version \" + pd.__version__)\n",
    "print(\"Matplotlib version \" + matplotlib.__version__)\n",
    "print(\"Seaborn version \" + sns.__version__)\n",
    "print(\"Imblance version \" +imblearn.__version__)\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Specifying which nodes should be run interactively\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Data loading function\n",
    "\n",
    "def load(sig_filename, bkg_filename, category, features):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    https://www.kaggle.com/wiki/MultiClassLogLoss\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sig_filename : array, shape = [n_samples]\n",
    "            true class, intergers in [0, n_classes - 1)\n",
    "    bkg_filename : array, shape = [n_samples, n_classes]\n",
    "    category: string\n",
    "    features: array, shape = [n_features]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pandas.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    signal = root2array(sig_filename, category, features)\n",
    "    signal = rec2array(signal)\n",
    "\n",
    "    backgr = root2array(bkg_filename, category, features)\n",
    "    backgr = rec2array(backgr)\n",
    "\n",
    "    # for sklearn data is usually organised\n",
    "    # into one 2D array of shape (n_samples x n_features)\n",
    "    # containing all the data and one array of categories\n",
    "    # of length n_samples\n",
    "    X = np.concatenate((signal, backgr))\n",
    "    y = np.concatenate((np.ones(signal.shape[0]), np.zeros(backgr.shape[0])))\n",
    "\n",
    "    # convert to numpy ndarray into pandas dataframe\n",
    "    dataframe_X = pd.DataFrame(data=X, columns=features)\n",
    "    dataframe_y = pd.DataFrame(data=y, columns=['y'])\n",
    "\n",
    "    data = pd.concat([dataframe_X, dataframe_y], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of events: 11502\n",
      "Number of features: 14\n",
      "\n",
      "Wall time to read in file input:  0.192630052567\n",
      "CPU time to read in file input:  0.188549\n"
     ]
    }
   ],
   "source": [
    "## Load input data files\n",
    "\n",
    "# Feature names\n",
    "branch_names = \"\"\"mass_tag_tag_min_deltaR,median_mass_jet_jet,\n",
    "    maxDeltaEta_tag_tag,mass_higgsLikeDijet,HT_tags,\n",
    "    btagDiscriminatorAverage_tagged,mass_jet_tag_min_deltaR,\n",
    "    mass_jet_jet_min_deltaR,mass_tag_tag_max_mass,maxDeltaEta_jet_jet,\n",
    "    centrality_jets_leps,centrality_tags,globalTimesEventWeight\"\"\".split(\",\")\n",
    "\n",
    "features = [c.strip() for c in branch_names]\n",
    "features = (b.replace(\" \", \"_\") for b in features)\n",
    "features = list(b.replace(\"-\", \"_\") for b in features)\n",
    "\n",
    "wall = time.time()\n",
    "process = time.clock()\n",
    "\n",
    "# Load dataset\n",
    "signal_sample = \"combined/signalMC.root\"\n",
    "background_sample = \"combined/backgroundMC.root\"\n",
    "tree_category = \"event_mvaVariables_step7_cate4\"\n",
    "\n",
    "data = load(signal_sample, background_sample, tree_category, features)\n",
    "\n",
    "print \"Total number of events: {}\\nNumber of features: {}\".format(data.shape[0], data.shape[1])\n",
    "\n",
    "# Store a copy for later use\n",
    "df_archived = data.copy(deep=True)\n",
    "\n",
    "print \"\\nWall time to read in file input: \", time.time()-wall\n",
    "print \"CPU time to read in file input: \", time.clock()-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Function to extract class label counts and percentage\n",
    "\n",
    "def class_info(classes):\n",
    "    # Store the number of signal and background events\n",
    "    class_count = {}\n",
    "    counts = Counter(classes)\n",
    "    total = sum(counts.values())\n",
    "\n",
    "    for cls in counts.keys():\n",
    "        class_count[class_label[cls]] = counts[cls]\n",
    "        print(\"%10s: %7d  =  % 5.1f%%\" % (class_label[cls], counts[cls], float(counts[cls])/float((total))*100.0))\n",
    "\n",
    "    return (class_count[\"signal\"], class_count[\"background\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background:    6777  =   58.9%\n",
      "    signal:    4725  =   41.1%\n"
     ]
    }
   ],
   "source": [
    "## Determine class label counts and percentages\n",
    "\n",
    "class_label = {0.0: \"background\", 1.0: \"signal\"}\n",
    "class_info(data.y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Create features dataframe and target array\n",
    "\n",
    "df_X = data.drop(\"y\", axis=1, inplace=False)\n",
    "df_y = data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot AUC for ROC curve for several classifiers out-of-the-box\n",
    "\n",
    "# Set feature scaling type\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# prepare models: create a mapping of ML classifier name to algorithm\n",
    "pipe_classifiers = {\n",
    "    'SVC':  make_pipeline(scaler, SVC(class_weight=\"balanced\")), # sample_weight included\n",
    "    'LogisticRegression'    : make_pipeline(scaler, LogisticRegression(class_weight=\"balanced\")),\n",
    "    'AdaBoostClassifier'    : make_pipeline(None,   AdaBoostClassifier()),\n",
    "    'RandomForestClassifier': make_pipeline(None,   RandomForestClassifier(min_samples_leaf=10)),\n",
    "    'DecisionTreeClassifier': make_pipeline(None,   DecisionTreeClassifier(min_samples_leaf=10,\n",
    "                                                                           class_weight=\"balanced\")),\n",
    "    'GradientBoostingClassifier': make_pipeline(None,   GradientBoostingClassifier(min_samples_leaf=10)),\n",
    "    'BaggingClassifier': make_pipeline(None,   BaggingClassifier(n_estimators=1000)),\n",
    "    'ExtraTreesClassifier' :  make_pipeline(None, ExtraTreesClassifier(min_samples_leaf=10)),#,\n",
    "    #'LinearDiscriminantAnalysis':  make_pipeline(scaler, LinearDiscriminantAnalysis()),\n",
    "    #'KNeighborsClassifier':  make_pipeline(scaler, KNeighborsClassifier()),\n",
    "    #'GaussianNB' :  make_pipeline(scaler, GaussianNB()), \n",
    "    #'MLPClassifier':  make_pipeline(scaler, MLPClassifier()), \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Early stopping plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Validation curve definition\n",
    "\n",
    "def early_stopping_curve(clf, X, y):\n",
    "    \"\"\"Early stopping curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : array, shape = [n_samples]\n",
    "            true class, intergers in [0, n_classes - 1)\n",
    "    X : array, shape = [n_samples, n_classes]\n",
    "    y : array, shape = [n_samples, n_classes]\n",
    "    Returns\n",
    "    -------\n",
    "    plt : matplotlib\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split data into a development and evaluation set\n",
    "    X_dev,X_eval, y_dev, y_eval = train_test_split(X, y, test_size=.33,\n",
    "                                                   random_state=seed)\n",
    "    # Split development set into a train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.33,\n",
    "                                                        random_state=seed+31415)\n",
    "    \n",
    "    sample_weight_train = X_train[\"globalTimesEventWeight\"].values\n",
    "    \n",
    "    sample_weight_test = X_test[\"globalTimesEventWeight\"].values\n",
    "\n",
    "    \n",
    "    \n",
    "    X_train = X_train.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "    X_test = X_test.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "    \n",
    "    clf.fit(X_train, y_train, **{'sample_weight': sample_weight_train}) \n",
    "\n",
    "    # Customize the major grid\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.grid(which='major', linestyle='-', linewidth='0.2', color='gray')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    test_score = np.empty(len(clf.estimators_))\n",
    "    train_score = np.empty(len(clf.estimators_))\n",
    "\n",
    "    for i, pred in enumerate(clf.staged_predict_proba(X_test)):\n",
    "        test_score[i] = 1-roc_auc_score(y_test, pred[:,1], sample_weight=sample_weight_test)\n",
    "\n",
    "    for i, pred in enumerate(clf.staged_predict_proba(X_train)):\n",
    "        train_score[i] = 1-roc_auc_score(y_train, pred[:,1], sample_weight=sample_weight_train)\n",
    "\n",
    "    best_iter = np.argmin(test_score)\n",
    "    learn = clf.get_params()['learning_rate']\n",
    "    depth = clf.get_params()['max_depth']\n",
    "        \n",
    "    test_line = plt.plot(test_score, label='test (1-roc_auc=%.3f)'%(test_score[best_iter]))\n",
    "\n",
    "    colour = test_line[-1].get_color()\n",
    "    plt.plot(train_score, '--', color=colour, \n",
    "             label='train (1-roc_auc=%.3f)\\nlearn=%.1f depth=%i'\n",
    "             %(train_score[best_iter],learn,depth))\n",
    "\n",
    "    plt.title(\"Early stopping curve\")\n",
    "    plt.xlabel(\"Number of boosting iterations\")\n",
    "    plt.ylabel(\"1 - area under ROC\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.axvline(x=best_iter, color=colour)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##  plot the early stopping curve for the fitted classifier\n",
    "# and check with the test set at which number of n_estimators we reach the minimum test error.\n",
    "\n",
    "wall = time.time()\n",
    "process = time.clock()\n",
    "\n",
    "# Set of hyper-parameter selected\n",
    "opts = dict(max_depth=3, \n",
    "            learning_rate=0.01, \n",
    "            n_estimators=1200)\n",
    "\n",
    "clf = GradientBoostingClassifier(**opts)\n",
    "\n",
    "early_stopping_curve(clf, df_X, df_y)\n",
    "\n",
    "print \"\\nWall time to generate early stopping plots: \", time.time()-wall\n",
    "print \"CPU time to generate early stopping plots: \", time.clock()-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature ranking and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Feature ranking \n",
    "\n",
    "def feature_ranking_plot(X, importances, std, indices, title):\n",
    "\n",
    "    # Customize the major grid\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.grid(which='major', linestyle='-', linewidth='0.2', color='gray')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    X_tmp = X.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "\n",
    "    print(title)\n",
    "    for i in xrange(X_tmp.shape[1]):\n",
    "        print(\"%d. %s (%f)\" % (i + 1, X_tmp.columns[indices[i]], importances[indices[i]]))\n",
    "\n",
    "    # Plot the feature importances of the model\n",
    "    plt.title(title)\n",
    "    plt.bar(range(X_tmp.shape[1]), importances[indices],\n",
    "            color=\"r\", yerr=std, align=\"center\") \n",
    "    plt.xticks(range(X_tmp.shape[1]), X_tmp.columns[indices], rotation='vertical')\n",
    "    plt.xlim([-1, X_tmp.shape[1]])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Extract feature selection\n",
    "\n",
    "def extract_feature_selected(clf, X, y):\n",
    "    \n",
    "    # Split data into a development and evaluation set\n",
    "    X_dev,X_eval, y_dev, y_eval = train_test_split(df_X, df_y, test_size=.33, \n",
    "                                                   random_state=seed)\n",
    "    # Split development set into a train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.33,\n",
    "                                                        random_state=seed+31415)\n",
    "\n",
    "    sample_weight = X_train[\"globalTimesEventWeight\"].values\n",
    "    \n",
    "    X_train = X_train.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "    X_test = X_test.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "    \n",
    "    clf.fit(X_train,y_train, **{clf.steps[1][0].lower()+'__sample_weight': sample_weight}) \n",
    "    \n",
    "    select_indices = clf.named_steps['SELECT'].transform(\n",
    "    np.arange(len(X_train.columns)).reshape(1, -1))\n",
    "\n",
    "    feature_names = X_train.columns[select_indices]\n",
    "    \n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Feature selection\n",
    "\n",
    "def features_selection_model_performance(clf, X, y, parameter_set):\n",
    "\n",
    "    # Customize the major grid\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.grid(which='major', linestyle='-', linewidth='0.2', color='gray')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    this_scores = list()\n",
    "    score_means = list()\n",
    "    score_stds = list()\n",
    "\n",
    "    params = {'SELECT__k': 'top k features', \n",
    "              'SELECT__threshold': 'feature threshold',\n",
    "              'SELECT__n_features_to_select': 'n features to select',\n",
    "              'SELECT__percentile': 'percentile',\n",
    "              'SELECT__cv': 'k-fold',\n",
    "              'SELECT__selection_threshold':'selection threshold'}\n",
    "\n",
    "    label = [keyname for keyname in clf.get_params().keys() if keyname in params.keys()][0]\n",
    "    \n",
    "    sample_weights = X[\"globalTimesEventWeight\"].values\n",
    "    \n",
    "    for k in parameter_set:\n",
    "\n",
    "        param = {label: k}\n",
    "        clf.set_params(**param) \n",
    "        \n",
    "        # Compute cross-validation score using 1 CPU\n",
    "        this_scores = cross_val_score(clf, \n",
    "                                      X.drop('globalTimesEventWeight', axis=1, inplace=False), y,\n",
    "                                      cv=3, n_jobs=1, \n",
    "                                      fit_params={'classifier__sample_weight': sample_weights})\n",
    "        score_means.append(this_scores.mean())\n",
    "        score_stds.append(this_scores.std())\n",
    "\n",
    "    plt.errorbar(parameter_set, score_means, np.array(score_stds))\n",
    "\n",
    "    model = clf.steps[1][0]\n",
    "\n",
    "    title = 'Performance of the {}-{} varying for features selected'.format(model,\n",
    "                                                                            clf.get_params().keys()[1])\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(params[label])\n",
    "    plt.ylabel('Prediction rate')\n",
    "\n",
    "    print  extract_feature_selected(clf, X, y).values[0]\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Univariate Statistics: variance threshold\n",
    "\n",
    "process = time.time()\n",
    "process = time.clock()\n",
    "\n",
    "# Sample weights\n",
    "sample_weights = df_X[\"globalTimesEventWeight\"].values\n",
    "\n",
    "# Removing features with low variance\n",
    "select = VarianceThreshold(threshold=0.0)\n",
    "\n",
    "# Configure pipeline \n",
    "pipe = Pipeline([('SELECT', select), ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Features selected by variance threshold\n",
    "_=pipe.fit(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y,\n",
    "         **{'classifier__sample_weight': sample_weights})\n",
    "\n",
    "# Extract feature importances, standard deviations, and indices\n",
    "importances = pipe.named_steps[\"SELECT\"].variances_\n",
    "std = np.std([importance for importance in importances], axis=0)*np.ones(len(importances))\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot feature ranking\n",
    "feature_ranking_plot(df_X, importances, std, indices, \"Feature importances based on variance ranking\")\n",
    "\n",
    "# Variance thresholds\n",
    "threshold = [0.0, 0.1, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "# Plot feature selection\n",
    "features_selection_model_performance(pipe, df_X, df_y, threshold)\n",
    "\n",
    "print \"Wall time to produce feature ranking plots: \", time.time()-wall\n",
    "print \"CPU time to prodduce feature ranking plots: \", time.clock()-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Univariate Statistics: percentile (of the highest feature scores)\n",
    "\n",
    "process = time.time()\n",
    "process = time.clock()\n",
    "\n",
    "# Sample weights\n",
    "sample_weights = df_X[\"globalTimesEventWeight\"].values\n",
    "\n",
    "# Univariate feature selection according to a percentile of the highest scores\n",
    "select = feature_selection.SelectPercentile(f_classif)\n",
    "\n",
    "# Configure pipeline\n",
    "pipe = Pipeline([('SELECT', select), ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Features selected based on k-highest scores\n",
    "_=pipe.fit(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y,\n",
    "         **{'classifier__sample_weight': sample_weights})\n",
    "\n",
    "# Extract feature importances, standard deviations, and indices\n",
    "importances = pipe.named_steps[\"SELECT\"].scores_\n",
    "std = np.std([score for score in importances], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot feature ranking\n",
    "feature_ranking_plot(df_X, importances, std, indices, \"Feature importances based percentile of the highest feature scores classification ranking\")\n",
    "\n",
    "# Percentile selections\n",
    "percentiles = [6, 10, 15, 20, 30, 40, 60, 80, 100]\n",
    "\n",
    "# Plot feature selection\n",
    "features_selection_model_performance(pipe, df_X, df_y, percentiles)\n",
    "\n",
    "print \"Wall time to produce feature ranking plots: \", time.time()-wall\n",
    "print \"CPU time to prodduce feature ranking plots: \", time.clock()-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Univariate Statistics: K-best features\n",
    "\n",
    "process = time.time()\n",
    "process = time.clock()\n",
    "\n",
    "# Sample weights\n",
    "sample_weights = df_X[\"globalTimesEventWeight\"].values\n",
    "\n",
    "#  Univariate feature selection based on the k highest scores\n",
    "select = SelectKBest(score_func=f_classif, k=6)\n",
    "\n",
    "# Configure pipeline \n",
    "pipe = Pipeline([('SELECT', select), ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Features selected based on k-highest scores\n",
    "_=pipe.fit(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y,\n",
    "         **{'classifier__sample_weight': sample_weights})\n",
    "\n",
    "# Extract feature importances, standard devations, and indices\n",
    "importances = pipe.named_steps[\"SELECT\"].scores_\n",
    "std = np.std([importance for importance in importances], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot feature ranking\n",
    "feature_ranking_plot(df_X, importances, std, indices, \"Feature importances based k-best features classification ranking\")\n",
    "\n",
    "# K-best features\n",
    "k = [2, 4, 6, 8, 10, 12]\n",
    "\n",
    "# Plot feature selection\n",
    "features_selection_model_performance(pipe, df_X, df_y, k)\n",
    "\n",
    "\n",
    "print \"Wall time to produce feature ranking plots: \", time.time()-wall\n",
    "print \"CPU time to prodduce feature ranking plots: \", time.clock()-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Model-Based Feature Selection: SelectFromModel (RandomForrestClassifier)\n",
    "\n",
    "# The SelectFromModel class selects all features that have an importance measure \n",
    "# of the feature (as provided by the supervised model) greater than the provided \n",
    "# threshold. \n",
    "\n",
    "process = time.time()\n",
    "process = time.clock()\n",
    "\n",
    "# Sample weights\n",
    "sample_weights = df_X[\"globalTimesEventWeight\"].values\n",
    "\n",
    "# Selection using SelectFromModel based on RandomForestClassifier  \n",
    "select = SelectFromModel(RandomForestClassifier(n_estimators=10, random_state=seed), threshold=\"median\")\n",
    "\n",
    "# Configure pipeline\n",
    "pipe = Pipeline([('SELECT', select), ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Features selected by SelectFromModel using the RandomForestClassifier\n",
    "_=pipe.fit(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y,\n",
    "         **{'classifier__sample_weight': sample_weights})\n",
    "\n",
    "# Extract feature importances, standard deviations, and indices\n",
    "importances = pipe.named_steps[\"SELECT\"].estimator_.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in pipe.named_steps[\"SELECT\"].estimator_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot feature ranking\n",
    "feature_ranking_plot(df_X, importances, std, indices, \"RandomForestClassifier model-based feature importances ranking\")\n",
    "\n",
    "# Select n features\n",
    "#p = [\"mean\", \"median\"]\n",
    "p = [0.0001, 0.0005, 0.001, 0.01, 0.1]\n",
    "\n",
    "# Plot feature selection\n",
    "features_selection_model_performance(pipe, df_X, df_y, p)\n",
    "\n",
    "\n",
    "print \"Wall time to produce feature ranking plots: \", time.time()-wall\n",
    "print \"CPU time to prodduce feature ranking plots: \", time.clock()-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Model-Based Feature Selection: SelectFromModel (ExtraTreesClassifier)\n",
    "\n",
    "process = time.time()\n",
    "process = time.clock()\n",
    "\n",
    "# Sample weights\n",
    "sample_weights = df_X[\"globalTimesEventWeight\"].values\n",
    "\n",
    "# Selection using select from model based on extra trees classifier\n",
    "select = SelectFromModel(ExtraTreesClassifier(random_state=seed), threshold=\"median\")\n",
    "\n",
    "# Configure pipeline\n",
    "pipe = Pipeline([('SELECT', select), ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Features selected by SelectFromModel using the ExtraTreesClassifier\n",
    "_=pipe.fit(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y,\n",
    "         **{'classifier__sample_weight': sample_weights})\n",
    "\n",
    "# Extract feature importances, standard deviations, and indices\n",
    "importances = pipe.named_steps[\"SELECT\"].estimator_.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in pipe.named_steps[\"SELECT\"].estimator_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot feature ranking\n",
    "feature_ranking_plot(df_X, importances, std, indices, \"ExtraTree Model-based feature importances ranking\")\n",
    "\n",
    "# Selection based on threshold\n",
    "threshold = [0.001, 0.01, 0.017, 0.019] \n",
    "\n",
    "# Plot feature selection\n",
    "features_selection_model_performance(pipe, df_X, df_y, threshold)\n",
    "\n",
    "\n",
    "print \"\\nWall time to generate features selection performance plots: \", time.time()-wall\n",
    "print \"CPU time to generate features selection performance plots: \", time.clock()-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Iterative Feature Selection: Recursive feature elimination (without cross-validation)\n",
    "\n",
    "process = time.time()\n",
    "process = time.clock()\n",
    "\n",
    "# Sample weights\n",
    "sample_weights = df_X[\"globalTimesEventWeight\"].values\n",
    "\n",
    "# Recursive feature elimination \n",
    "select = RFE(estimator=RandomForestClassifier(), step=1)\n",
    "\n",
    "# Configure pipeline\n",
    "pipe = Pipeline([('SELECT', select), ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Features selected based on RFE ranking\n",
    "_=pipe.fit(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y,\n",
    "         **{'classifier__sample_weight': sample_weights})\n",
    "\n",
    "# Extract feature ranking, standard deviations, and indices\n",
    "importances = pipe.named_steps[\"SELECT\"].ranking_\n",
    "std = np.std([importance for importance in importances], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "             \n",
    "# n features to select\n",
    "n_features_to_select = [2, 3, 5, 7]\n",
    "\n",
    "# Plot feature ranking\n",
    "feature_ranking_plot(df_X, importances, std, indices, \"RFE model-based feature importances ranking\")\n",
    "\n",
    "# Plot feature selection\n",
    "features_selection_model_performance(pipe, df_X, df_y, n_features_to_select)\n",
    "\n",
    "print \"Wall time to produce feature ranking plots: \", time.time()-wall\n",
    "print \"CPU time to prodduce feature ranking plots: \", time.clock()-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Iterative Feature Selection: Recursive feature elimination with cross-validation\n",
    "\n",
    "process = time.time()\n",
    "process = time.clock()\n",
    "\n",
    "# Sample weights\n",
    "sample_weights = df_X[\"globalTimesEventWeight\"].values\n",
    "\n",
    "# Recursive feature elimination (RFE) with cross-validation \n",
    "select = RFECV(estimator=RandomForestClassifier(), step=1, \n",
    "               cv=StratifiedKFold(3), scoring='accuracy')\n",
    "\n",
    "# Configure pipeline\n",
    "pipe = Pipeline([('SELECT', select), ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Features selected based on k-highest scores\n",
    "_=pipe.fit(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y,\n",
    "         **{'classifier__sample_weight': sample_weights})\n",
    "\n",
    "# Extract feature importances, standard deviations, and indices\n",
    "importances = pipe.named_steps[\"SELECT\"].ranking_\n",
    "std = np.std([importance for importance in importances], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot feature ranking\n",
    "feature_ranking_plot(df_X, importances, std, indices, \"RFECV model-based feature importances ranking\")\n",
    "\n",
    "# Extract feature selection\n",
    "pipe.fit(df_X, df_y)\n",
    "\n",
    "kfold = [3, 5]\n",
    "\n",
    "# Plot feature selection\n",
    "features_selection_model_performance(pipe, df_X, df_y, kfold)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % pipe.named_steps[\"SELECT\"].n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "_=plt.figure()\n",
    "_=plt.xlabel(\"Number of features selected\")\n",
    "_=plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "_=plt.plot(range(1, len(pipe.named_steps[\"SELECT\"].grid_scores_) + 1), pipe.named_steps[\"SELECT\"].grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print \"Wall time to produce feature ranking plots: \", time.time()-wall\n",
    "print \"CPU time to prodduce feature ranking plots: \", time.clock()-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model building: feature scaling, selection, hyper-parameter optimization, and final model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Standard nested k-fold cross-validation\n",
    "\n",
    "def nestedGridSearchCV(Classifier, X, y, outer_cv, inner_cv, \n",
    "                       parameter_grid, scoring=\"accuracy\"):\n",
    "    \"\"\"Nested k-fold crossvalidation.\"\"\"\n",
    "    \n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    ----------\n",
    "    Classifier : array, shape = [n_samples]\n",
    "            true class, intergers in [0, n_classes - 1)\n",
    "    X : array, shape = [n_samples, n_classes]\n",
    "    y : array, shape = [n_samples, n_classes]\n",
    "    outer_cv:  shape = [n_samples, n_classes]\n",
    "    inner_cv:  shape = [n_samples, n_classes]\n",
    "    parameter_grid: shape = [n_samples, n_classes]\n",
    "    scoring:   shape = [n_samples, n_classes]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Grid classifier: classifier re-fitted to full dataset\n",
    "    \"\"\"    \n",
    "    \n",
    "    \n",
    "    outer_scores = []\n",
    "    \n",
    "    for training_samples, test_samples in outer_cv.split(X, y):\n",
    "\n",
    "        # Training datasets\n",
    "        x_training_temp = pd.DataFrame(X.iloc[training_samples], columns=features)\n",
    "\n",
    "        x_training = x_training_temp.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "        y_training = pd.Series(y.iloc[training_samples])\n",
    "\n",
    "        # Extract sample weight\n",
    "        weights_training = x_training_temp[\"globalTimesEventWeight\"].values\n",
    "\n",
    "        # Testing datasets\n",
    "        x_testing_temp = pd.DataFrame(X.iloc[test_samples], columns=features)\n",
    "\n",
    "        x_testing = x_testing_temp.drop('globalTimesEventWeight', axis=1, inplace=False)\n",
    "        y_testing = pd.Series(y.iloc[test_samples])\n",
    "\n",
    "        # set up grid search configuration\n",
    "        cv = GridSearchCV(estimator=Classifier, param_grid=parameter_grid,\n",
    "                          cv=inner_cv, scoring=\"accuracy\", \n",
    "                          n_jobs=-1,\n",
    "                          fit_params={\"classifier__sample_weight\": weights_training})\n",
    "                         \n",
    "        # train on the training set\n",
    "        cv.fit(x_training, y_training)\n",
    "        \n",
    "        # evaluate\n",
    "        outer_scores.append(cv.score(x_testing, y_testing))\n",
    "\n",
    "    # Print final model evaluation (i.e. mean cross-validation scores)\n",
    "    print \"Final model evaluation (mean cross-val scores):\\n\", np.array(outer_scores).mean()\n",
    "    \n",
    "    # note: the scoring is being done without the weights associated with X\n",
    "    # fit model to entire training dataset (i.e tuning & validation dataset)\n",
    "    cv.best_estimator_.fit(X.drop('globalTimesEventWeight', axis=1, inplace=False), y,\n",
    "                           **{\"classifier__sample_weight\": X[\"globalTimesEventWeight\"].values})\n",
    "    \n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Setup common configuration: cross-validation type, feature scaling, and model pipeline \n",
    "\n",
    "# Standard K-Fold cross-validation\n",
    "k_fold=5\n",
    "outer_kfold_cv = KFold(n_splits=k_fold, shuffle=True, random_state=seed)\n",
    "inner_kfold_cv = KFold(n_splits=k_fold-1, shuffle=True, random_state=seed)\n",
    "\n",
    "# preprocessing using 0-1 scaling by removing the mean and scaling to unit variance \n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Default pipeline setup with dummy place holder steps\n",
    "pipe = Pipeline([('feature_scaling', None), \n",
    "                 ('feature_selection', None), \n",
    "                 ('classifier', DummyClassifier())]\n",
    "               )\n",
    "\n",
    "# Split data into a development and evaluation set\n",
    "X_dev,X_eval, y_dev,y_eval = train_test_split(df_X, df_y,\n",
    "                                              test_size=0.33, random_state=seed)\n",
    "# Split development set into a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.33,\n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "select = VarianceThreshold()\n",
    "\n",
    "# create classifier for use in scikit-learn\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# prepare models: create a mapping of ML classifier name to algorithm\n",
    "param_grid = [\n",
    "    {'classifier': [model],\n",
    "     'classifier__n_estimators': [100],\n",
    "     'classifier__learning_rate': [0.1],\n",
    "     'feature_selection': [select],\n",
    "     'feature_selection__threshold': [0.4],\n",
    "     'feature_scaling': [scaler]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = nestedGridSearchCV(Classifier=pipe,\n",
    "                          X=X_train, y=y_train, \n",
    "                          outer_cv=outer_kfold_cv, inner_cv=inner_kfold_cv, \n",
    "                          parameter_grid=param_grid, \n",
    "                          scoring=\"roc_auc\")\n",
    "\n",
    "y_pred = grid.predict(X_test.drop('globalTimesEventWeight', axis=1, inplace=False))\n",
    "report = classification_report( y_test, y_pred )\n",
    "print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Evaluate best selected model\n",
    "\n",
    "print(\"Pipeline steps:\\n{}\".format(grid.best_estimator_.steps))\n",
    "\n",
    "# extract the first step \n",
    "components = grid.best_estimator_.named_steps[\"feature_scaling\"]\n",
    "print(\"components: {}\".format(components))\n",
    "classifier = grid.best_estimator_.named_steps[\"classifier\"]\n",
    "print(\"GradientBoostingClassifier classifier step:\\n{}\".format(classifier))\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_)) \n",
    "print(\"Test set score: {:.2f}\".format(grid.best_estimator_.score(df_X.drop('globalTimesEventWeight', \n",
    "                                                                           axis=1, inplace=False), df_y))) \n",
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "select = SelectKBest(k=8)\n",
    "\n",
    "# create classifier for use in scikit-learn\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# prepare models: create a mapping of ML classifier name to algorithm\n",
    "param_grid = [\n",
    "    {'classifier': [model],\n",
    "     'classifier__n_estimators': [100],\n",
    "     'classifier__learning_rate': [0.1],\n",
    "     'feature_selection': [select],\n",
    "     'feature_selection__k': [10],\n",
    "     'feature_scaling': [scaler]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = nestedGridSearchCV(Classifier=pipe,\n",
    "                          X=X_train, y=y_train, \n",
    "                          outer_cv=outer_kfold_cv, inner_cv=inner_kfold_cv, \n",
    "                          parameter_grid=param_grid, \n",
    "                          scoring=\"roc_auc\")\n",
    "\n",
    "\n",
    "y_pred = grid.predict(X_test.drop('globalTimesEventWeight', axis=1, inplace=False))\n",
    "report = classification_report( y_test, y_pred )\n",
    "print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Evaluate best selected model\n",
    "\n",
    "print(\"Pipeline steps:\\n{}\".format(grid.best_estimator_.steps))\n",
    "\n",
    "# extract the first step \n",
    "components = grid.best_estimator_.named_steps[\"feature_scaling\"]\n",
    "print(\"components: {}\".format(components))\n",
    "classifier = grid.best_estimator_.named_steps[\"classifier\"]\n",
    "print(\"GradientBoostingClassifier classifier step:\\n{}\".format(classifier))\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_)) \n",
    "print(\"Test set score: {:.2f}\".format(grid.best_estimator_.score(df_X.drop('globalTimesEventWeight', \n",
    "                                                                           axis=1, inplace=False), df_y))) \n",
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "select = feature_selection.SelectPercentile(f_classif)\n",
    "\n",
    "# create classifier for use in scikit-learn\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# prepare models: create a mapping of ML classifier name to algorithm\n",
    "param_grid = [\n",
    "    {'classifier': [model],\n",
    "     'classifier__n_estimators': [100],\n",
    "     'classifier__learning_rate': [0.1],\n",
    "     'feature_selection': [select],\n",
    "     'feature_selection__percentile': [90],\n",
    "     'feature_scaling': [scaler]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = nestedGridSearchCV(Classifier=pipe,\n",
    "                          X=X_train, y=y_train, \n",
    "                          outer_cv=outer_kfold_cv, inner_cv=inner_kfold_cv, \n",
    "                          parameter_grid=param_grid, \n",
    "                          scoring=\"roc_auc\")\n",
    "\n",
    "y_pred = grid.predict(X_test.drop('globalTimesEventWeight', axis=1, inplace=False))\n",
    "report = classification_report( y_test, y_pred )\n",
    "print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Evaluate best selected model\n",
    "\n",
    "print(\"Pipeline steps:\\n{}\".format(grid.best_estimator_.steps))\n",
    "\n",
    "# extract the first step \n",
    "components = grid.best_estimator_.named_steps[\"feature_scaling\"]\n",
    "print(\"components: {}\".format(components))\n",
    "classifier = grid.best_estimator_.named_steps[\"classifier\"]\n",
    "print(\"GradientBoostingClassifier classifier step:\\n{}\".format(classifier))\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_)) \n",
    "print(\"Test set score: {:.2f}\".format(grid.best_estimator_.score(df_X.drop('globalTimesEventWeight', \n",
    "                                                                           axis=1, inplace=False), df_y))) \n",
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "select = RFE(estimator=RandomForestClassifier(), n_features_to_select=8, step=1)\n",
    "\n",
    "# create classifier for use in scikit-learn\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# prepare models: create a mapping of ML classifier name to algorithm\n",
    "param_grid = [\n",
    "    {'classifier': [model],\n",
    "     'classifier__n_estimators': [100],\n",
    "     'classifier__learning_rate': [0.1],\n",
    "     'feature_selection': [select],\n",
    "     'feature_selection__n_features_to_select': [10],\n",
    "     'feature_scaling': [scaler]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = nestedGridSearchCV(Classifier=pipe,\n",
    "                          X=X_train, y=y_train, \n",
    "                          outer_cv=outer_kfold_cv, inner_cv=inner_kfold_cv, \n",
    "                          parameter_grid=param_grid, \n",
    "                          scoring=\"roc_auc\")\n",
    "\n",
    "y_pred = grid.predict(X_test.drop('globalTimesEventWeight', axis=1, inplace=False))\n",
    "report = classification_report( y_test, y_pred )\n",
    "print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Evaluate best selected model\n",
    "\n",
    "print(\"Pipeline steps:\\n{}\".format(grid.best_estimator_.steps))\n",
    "\n",
    "# extract the first step \n",
    "components = grid.best_estimator_.named_steps[\"feature_scaling\"]\n",
    "print(\"components: {}\".format(components))\n",
    "classifier = grid.best_estimator_.named_steps[\"classifier\"]\n",
    "print(\"GradientBoostingClassifier classifier step:\\n{}\".format(classifier))\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_)) \n",
    "print(\"Test set score: {:.2f}\".format(grid.best_estimator_.score(df_X.drop('globalTimesEventWeight',\n",
    "                                                                           axis=1, inplace=False), df_y))) \n",
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "select = RFECV(estimator=RandomForestClassifier(), step=1,  \n",
    "               cv=StratifiedKFold(3), scoring='accuracy')\n",
    "\n",
    "# create classifier for use in scikit-learn\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# prepare models: create a mapping of ML classifier name to algorithm\n",
    "param_grid = [\n",
    "    {'classifier': [model],\n",
    "     'classifier__n_estimators': [100],\n",
    "     'classifier__learning_rate': [0.1],\n",
    "     'feature_selection': [select],\n",
    "     'feature_selection__cv': [7],\n",
    "     'feature_scaling': [scaler]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = nestedGridSearchCV(Classifier=pipe,\n",
    "                          X=X_train, y=y_train, \n",
    "                          outer_cv=outer_kfold_cv, inner_cv=inner_kfold_cv, \n",
    "                          parameter_grid=param_grid, \n",
    "                          scoring=\"roc_auc\")\n",
    "\n",
    "y_pred = grid.predict(X_test.drop('globalTimesEventWeight', axis=1, inplace=False))\n",
    "report = classification_report( y_test, y_pred )\n",
    "print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Evaluate best selected model\n",
    "\n",
    "print(\"Pipeline steps:\\n{}\".format(grid.best_estimator_.steps))\n",
    "\n",
    "# extract the first step \n",
    "components = grid.best_estimator_.named_steps[\"feature_scaling\"]\n",
    "print(\"components: {}\".format(components))\n",
    "classifier = grid.best_estimator_.named_steps[\"classifier\"]\n",
    "print(\"GradientBoostingClassifier classifier step:\\n{}\".format(classifier))\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_)) \n",
    "print(\"Test set score: {:.2f}\".format(grid.best_estimator_.score(df_X.drop('globalTimesEventWeight', \n",
    "                                                                           axis=1, inplace=False), df_y))) \n",
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implementing a Weighted Majority Rule Ensemble Classifier\n",
    "\n",
    "In order to trained a set of equally well performing models and balance out their individual weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Esemble classifier\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)]\n",
    "voting='hard' #'soft'\n",
    "\n",
    "eclf = VotingClassifier(estimators=estimators, voting=voting, weights=[1,1,1])\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression',\n",
    "                                                 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "\n",
    "    scores = cross_val_score(clf, df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y, \n",
    "                             cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Handling unblanaced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Apply the random over-sampling\n",
    "ros = RandomOverSampler()\n",
    "X_overresampled, y_overresampled = ros.fit_sample(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y)\n",
    "\n",
    "# Apply the random under-sampling\n",
    "rus = RandomUnderSampler()\n",
    "X_underresampled, y_underresampled = rus.fit_sample(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y)\n",
    "\n",
    "# Apply SMOTE SVM\n",
    "sm = SMOTE(kind='svm')\n",
    "X_resampled, y_resampled = sm.fit_sample(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression',\n",
    "                                                 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "\n",
    "    scores = cross_val_score(clf, X_overresampled, y_overresampled, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression',\n",
    "                                                 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "\n",
    "    scores = cross_val_score(clf, X_underresampled, y_underresampled, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression',\n",
    "                                                 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "\n",
    "    scores = cross_val_score(clf, X_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hyper-parameter tuning:  Bayesian optimization using Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define objective loss function to minimize/maximize\n",
    "\n",
    "def objective(params):    \n",
    "    # Split development set into a train and test set\n",
    "    X_train, X_test, y_train, y_test= train_test_split(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y, test_size=0.33, random_state=42)\n",
    "\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "    \n",
    "    max_depth, learning_rate, max_features, min_samples_split, min_samples_leaf = params\n",
    "\n",
    "    clf.set_params(max_depth=max_depth,\n",
    "                   learning_rate=learning_rate,\n",
    "                   max_features=max_features,\n",
    "                   min_samples_split=min_samples_split, \n",
    "                   min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    #return -np.mean(cross_val_score(clf, X, y, cv=5, n_jobs=-1,\n",
    "    #                                scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "    #return np.mean(cross_val_score(clf, X, y, cv=5, n_jobs=-1, scoring=\"roc_auc\"))\n",
    "    shuffle = KFold(n_splits=5, shuffle=True)\n",
    "    score = cross_val_score(clf, X_train, y_train, cv=shuffle, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "    #return 1-score.mean()\n",
    "\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_features = df_X.drop('globalTimesEventWeight', axis=1, inplace=False).shape[1]\n",
    "\n",
    "parameters  = [(1, 4),                           # max_depth\n",
    "               (10**-2, 10**0, \"log-uniform\"),   # learning_rate  (sample from \"log-uniform\" distribution)\n",
    "               (9, n_features),                  # max_features\n",
    "               (2, 100),                         # min_samples_split\n",
    "               (1, 100)]                         # min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Optimize hyper-parameters of classifier\n",
    "\n",
    "process = time.time()\n",
    "process = time.clock()\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=50, random_state=0)\n",
    "\n",
    "clf_gp = gp_minimize(objective, parameters, n_calls=30, random_state=0)\n",
    "\n",
    "\"Best score=%.4f\" % clf_gp.fun\n",
    "\n",
    "print \"\\nWall time to generate classifier models: \", time.time()-wall\n",
    "print \"CPU time to generate classifier models: \", time.clock()-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"\"\"Best parameters:\n",
    "- max_depth=%d\n",
    "- learning_rate=%.6f\n",
    "- max_features=%d\n",
    "- min_samples_split=%d\n",
    "- min_samples_leaf=%d\"\"\" % (clf_gp.x[0], clf_gp.x[1], \n",
    "                            clf_gp.x[2], clf_gp.x[3], \n",
    "                            clf_gp.x[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_convergence(clf_gp);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split data into a development and evaluation set\n",
    "X_dev,X_eval, y_dev,y_eval = train_test_split(df_X, df_y,\n",
    "                                              test_size=0.33, random_state=seed)\n",
    "# Split development set into a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.33,\n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "space4rf = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,5)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(1,20)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "    #'scale': hp.choice('scale', [0, 1]),\n",
    "    #'normalize': hp.choice('normalize', [0, 1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    clf = RandomForestClassifier(**params)\n",
    "    \n",
    "    return cross_val_score(clf, X_train.drop('globalTimesEventWeight', axis=1, inplace=False), y_train).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best = 0\n",
    "\n",
    "def f(params):\n",
    "    global best\n",
    "    acc = hyperopt_train_test(params)\n",
    "    if acc > best:\n",
    "        best = acc\n",
    "    print 'new best:', best, params\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(f, space4rf, algo=tpe.suggest, max_evals=300, trials=trials)\n",
    "\n",
    "print 'best:'\n",
    "print best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "parameters = ['n_estimators', 'max_depth', 'max_features', 'criterion']\n",
    "f, axes = plt.subplots(nrows=2, ncols=3, figsize=(15,10))\n",
    "\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "for i, val in enumerate(parameters):\n",
    "    print i, val\n",
    "    xs = np.array([t['misc']['vals'][val] for t in trials.trials]).ravel()\n",
    "    ys = [-t['result']['loss'] for t in trials.trials]\n",
    "    #xs, ys = zip(sorted(zip(xs, ys)))\n",
    "    ys = np.array(ys)\n",
    "    axes[i/3,i%3].scatter(xs, ys, s=20, linewidth=0.01, alpha=0.5, c=cmap(float(i)/len(parameters)))\n",
    "    axes[i/3,i%3].set_title(val)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data into a development and evaluation set\n",
    "X_dev,X_eval, y_dev,y_eval = train_test_split(df_X.drop('globalTimesEventWeight', axis=1, inplace=False), df_y,\n",
    "                                              test_size=0.33, random_state=seed)\n",
    "# Split development set into a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.33,\n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Source: Optunity is a particle swarm implementation\n",
    "#       - http://optunity.readthedocs.io/en/latest/notebooks/notebooks/basic-nested-cv.html\n",
    "#       - http://optunity.readthedocs.io/en/latest/notebooks/notebooks/sklearn-automated-classification.html\n",
    "\n",
    "import optunity\n",
    "import optunity.metrics\n",
    "import sklearn.svm\n",
    "\n",
    "# score function: twice iterated 3-fold cross-validated accuracy\n",
    "@optunity.cross_validated(x=X_train.values, y=y_train.values, num_folds=3, num_iter=2)\n",
    "def svm_auc(x_train, y_train, x_test, y_test, logC, logGamma):\n",
    "    model = sklearn.svm.SVC(C=10 ** logC, gamma=10 ** logGamma).fit(x_train, y_train)\n",
    "    decision_values = model.decision_function(x_test)\n",
    "    return optunity.metrics.roc_auc(y_test, decision_values)\n",
    "\n",
    "# perform tuning\n",
    "hps, _, _ = optunity.maximize(svm_auc, num_evals=200, logC=[-5, 2], logGamma=[-5, 1])\n",
    "\n",
    "# train model on the full training set with tuned hyperparameters\n",
    "optimal_model = sklearn.svm.SVC(C=10 ** hps['logC'], gamma=10 ** hps['logGamma']).fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameters: {'logGamma': -4.266875728624809, 'C': 0.27960183016356593}\n",
      "Cross-validated AUROC after tuning: 0.708\n",
      "\n",
      "Hyperparameters: {'logGamma': -4.954473711339327, 'C': 2.2913673660180756}\n",
      "Cross-validated AUROC after tuning: 0.708\n",
      "\n",
      "Hyperparameters: {'logGamma': -4.963271692436976, 'C': 3.812090561946987}\n",
      "Cross-validated AUROC after tuning: 0.719\n",
      "\n",
      "Nested AUROC: 0.715\n"
     ]
    }
   ],
   "source": [
    "import optunity\n",
    "import optunity.cross_validation\n",
    "import optunity.metrics\n",
    "import sklearn.svm\n",
    "\n",
    "# outer cross-validation to estimate performance of whole pipeline\n",
    "@optunity.cross_validated(x=X_train.values, y=y_train.values, num_folds=3, strata=optunity.cross_validation.strata_by_labels(y_train.values))\n",
    "def nested_cv(x_train, y_train, x_test, y_test):\n",
    "\n",
    "    # inner cross-validation to estimate performance of a set of hyperparameters\n",
    "    @optunity.cross_validated(x=x_train, y=y_train, num_folds=2, num_iter=2,\n",
    "                              strata=optunity.cross_validation.strata_by_labels(y_train))\n",
    "    def inner_cv(x_train, y_train, x_test, y_test, C, logGamma):\n",
    "        # note that the x_train, ... variables in this function are not the same\n",
    "        # as within nested_cv!\n",
    "        model = sklearn.svm.SVC(C=C, gamma=10 ** logGamma).fit(x_train, y_train)\n",
    "        predictions = model.decision_function(x_test)\n",
    "        return optunity.metrics.roc_auc(y_test, predictions)\n",
    "\n",
    "    hpars, info, _ = optunity.maximize(inner_cv, num_evals=100,\n",
    "                                    C=[0, 10], logGamma=[-5, 1])\n",
    "    print('')\n",
    "    print('Hyperparameters: ' + str(hpars))\n",
    "    print('Cross-validated AUROC after tuning: %1.3f' % info.optimum)\n",
    "    model = sklearn.svm.SVC(C=hpars['C'], gamma=10 ** hpars['logGamma']).fit(x_train, y_train)\n",
    "    predictions = model.decision_function(x_test)\n",
    "    return optunity.metrics.roc_auc(y_test, predictions)\n",
    "\n",
    "auc = nested_cv(X_train.values, y_train.values, X_test.values, y_test.values)\n",
    "print('')\n",
    "print('Nested AUROC: %1.3f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameters: {'n_estimators': 87.3203125, 'max_depth': 2.23859375}\n",
      "Cross-validated AUROC after tuning: 0.707\n",
      "\n",
      "Hyperparameters: {'n_estimators': 81.2346358191097, 'max_depth': 2.297584075688575}\n",
      "Cross-validated AUROC after tuning: 0.694\n",
      "\n",
      "Hyperparameters: {'n_estimators': 61.01451133141119, 'max_depth': 2.7265039062499987}\n",
      "Cross-validated AUROC after tuning: 0.689\n",
      "\n",
      "Nested AUROC: 0.696\n"
     ]
    }
   ],
   "source": [
    "# outer cross-validation to estimate performance of whole pipeline\n",
    "@optunity.cross_validated(x=X_train.values, y=y_train.values, num_folds=3, \n",
    "                          strata=optunity.cross_validation.strata_by_labels(y_train.values))\n",
    "def nested_cv(x_train, y_train, x_test, y_test):\n",
    "\n",
    "    # inner cross-validation to estimate performance of a set of hyperparameters\n",
    "    @optunity.cross_validated(x=x_train, y=y_train, num_folds=2, num_iter=2,\n",
    "                              strata=optunity.cross_validation.strata_by_labels(y_train))\n",
    "    def inner_cv(x_train, y_train, x_test, y_test, n_estimators, max_depth):\n",
    "        # note that the x_train, ... variables in this function are not the same\n",
    "        # as within nested_cv!\n",
    "        model = RandomForestClassifier(min_samples_leaf=20, \n",
    "                                       n_estimators=int(n_estimators), max_depth=int(max_depth)).fit(x_train, y_train)\n",
    "        predictions = model.predict_proba(x_test)[:,1]\n",
    "        return optunity.metrics.roc_auc(y_test, predictions)\n",
    "\n",
    "    hpars, info, _ = optunity.maximize(inner_cv, num_evals=100, n_estimators=[50, 100], max_depth=[2, 3])\n",
    "    print('')\n",
    "    print('Hyperparameters: ' + str(hpars))\n",
    "    print('Cross-validated AUROC after tuning: %1.3f' % info.optimum)\n",
    "    model = RandomForestClassifier(min_samples_leaf=10,\n",
    "                                   n_estimators=int(hpars['n_estimators']), \n",
    "                                   max_depth=int(hpars['max_depth'])).fit(x_train, y_train)\n",
    "    predictions = model.predict_proba(x_test)[:,1]\n",
    "    \n",
    "    return optunity.metrics.roc_auc(y_test, predictions)\n",
    "\n",
    "auc = nested_cv(X_train.values, y_train.values, X_test.values, y_test.values)\n",
    "print('')\n",
    "print('Nested AUROC: %1.3f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Systematic steps to hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split data into a development and evaluation set\n",
    "X_dev,X_eval, y_dev,y_eval = train_test_split(df_X, df_y,\n",
    "                                              test_size=0.33, random_state=seed)\n",
    "# Split development set into a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.33,\n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Handle model fit and feature importance\n",
    "\n",
    "def modelfit(alg, y, X, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    \n",
    "    # Customize the major grid\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.grid(which='major', linestyle='-', linewidth='0.2', color='gray')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    #Extract sample weights from datasest\n",
    "    sample_weights = X[\"globalTimesEventWeight\"].values\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X.drop('globalTimesEventWeight', axis=1, inplace=False), y)\n",
    "        \n",
    "    #Predict training set:\n",
    "    predictions = alg.predict(X.drop('globalTimesEventWeight', axis=1, inplace=False))\n",
    "    predprob = alg.predict_proba(X.drop('globalTimesEventWeight', axis=1, inplace=False))[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, \n",
    "                                   X.drop('globalTimesEventWeight', axis=1, inplace=False), \n",
    "                                   y, cv=cv_folds, scoring='roc_auc',\n",
    "                                   fit_params={'sample_weight': sample_weights})\n",
    "    \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % accuracy_score(y, predictions, sample_weight=sample_weights)\n",
    "    print \"AUC Score (Train): %f\" % roc_auc_score(y, predprob, sample_weight=sample_weights)\n",
    "    \n",
    "    if performCV:\n",
    "        print \"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),\n",
    "                                                                                 np.std(cv_score),\n",
    "                                                                                 np.min(cv_score),\n",
    "                                                                                 np.max(cv_score))\n",
    "\n",
    "    # Extract features set\n",
    "    features_set = X.drop('globalTimesEventWeight', axis=1, inplace=False).columns.values\n",
    "    \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, features_set).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')\n",
    "        \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Out-of-the-box model\n",
    "\n",
    "gbm0 = GradientBoostingClassifier(random_state=10)\n",
    "\n",
    "modelfit(gbm0, y_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Fix learning rate and number of estimators for tuning tree-based parameters\n",
    "\n",
    "param_test1 = {'n_estimators':range(20, 200, 10)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=200,\n",
    "                                                               min_samples_leaf=50, max_depth=8, \n",
    "                                                               max_features='sqrt', subsample=0.8,random_state=10), \n",
    "                        param_grid = param_test1, scoring='roc_auc',n_jobs=-1, iid=False, cv=5)\n",
    "gsearch1.fit(X_train.drop('globalTimesEventWeight', axis=1, inplace=False), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Tuning tree-specific parameters\n",
    "\n",
    "param_test2 = {'max_depth':range(2, 10, 2), 'min_samples_split':range(100, 201, 20)}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30, max_features='sqrt',\n",
    "                                                               min_samples_leaf=50, subsample=0.8, random_state=10), \n",
    "                        param_grid = param_test2, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "gsearch2.fit(X_train.drop('globalTimesEventWeight', axis=1, inplace=False), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Take the max_depth of 7 as optimum and not try different values for higher min_samples_split. \n",
    "# It might not be the best idea always but here if you observe the output closely, \n",
    "# max_depth of 7 works better in most of the cases. \n",
    "# Also, we can test for 5 values of min_samples_leaf, from 30 to 70 in steps of 10, \n",
    "# along with higher min_samples_split.\n",
    "\n",
    "param_test3 = {'min_samples_split':range(100, 201, 20), 'min_samples_leaf':range(25,201,25)}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30,\n",
    "                                                               max_depth=6,max_features='sqrt', subsample=0.8, \n",
    "                                                               random_state=10), \n",
    "                        param_grid = param_test3, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "gsearch3.fit(X_train.drop('globalTimesEventWeight', axis=1, inplace=False), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Here we get the optimum values as 100 for min_samples_split and 25 for min_samples_leaf. \n",
    "# Also, we can see the CV score increasing to 0.73264671016122429 now.\n",
    "# Let's fit the model again on this and have a look at the feature importance.\n",
    "\n",
    "modelfit(gsearch3.best_estimator_,  y_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "param_test4 = {'max_features':range(2, 12, 1)}\n",
    "gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30,max_depth=6, \n",
    "                                                               min_samples_split=100, min_samples_leaf=25, \n",
    "                                                               subsample=0.8, random_state=10),\n",
    "                        param_grid = param_test4, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "gsearch4.fit(X_train.drop('globalTimesEventWeight', axis=1, inplace=False), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tuning subsample and making models with lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## The next step would be try different subsample values. Lets take values 0.6,0.7,0.75,0.8,0.85,0.9.\n",
    "\n",
    "param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "gsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30, max_depth=6,\n",
    "                                                               min_samples_split=100, min_samples_leaf=25, \n",
    "                                                               subsample=0.8, random_state=10, max_features=3),\n",
    "param_grid = param_test5, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "gsearch5.fit(X_train.drop('globalTimesEventWeight', axis=1, inplace=False), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Lets decrease the learning rate to half, i.e. 0.05 with twice (30) the number of trees. \n",
    "\n",
    "gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.05, n_estimators=60,\n",
    "                                         max_depth=6, min_samples_split=100,\n",
    "                                         min_samples_leaf=25, subsample=0.8, \n",
    "                                         random_state=10, max_features=3)\n",
    "modelfit(gbm_tuned_1, y_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Now lets reduce to one-tenth of the original value, i.e. 0.01 for 30 trees.\n",
    "\n",
    "gbm_tuned_2 = GradientBoostingClassifier(learning_rate=0.01, n_estimators=30,\n",
    "                                         max_depth=6, min_samples_split=100,\n",
    "                                         min_samples_leaf=25, subsample=0.80, \n",
    "                                         random_state=10, max_features=3)\n",
    "\n",
    "modelfit(gbm_tuned_2,  y_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Lets decrease to one-twentieth of the original value, i.e. 0.005 for 1200 trees.\n",
    "\n",
    "gbm_tuned_3 = GradientBoostingClassifier(learning_rate=0.005, n_estimators=60,\n",
    "                                         max_depth=6, min_samples_split=100, \n",
    "                                         min_samples_leaf=25, subsample=0.80, \n",
    "                                         random_state=10, max_features=3,\n",
    "                                         warm_start=True)\n",
    "\n",
    "modelfit(gbm_tuned_3, y_train, X_train, performCV=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Here we see that the score reduced very slightly. So lets run for 1500 trees.\n",
    "\n",
    "gbm_tuned_4 = GradientBoostingClassifier(learning_rate=0.005, n_estimators=100,\n",
    "                                         max_depth=6, min_samples_split=100, \n",
    "                                         min_samples_leaf=25, subsample=0.80, \n",
    "                                         random_state=10, max_features=3,\n",
    "                                         warm_start=True)\n",
    "modelfit(gbm_tuned_4,  y_train, X_train, performCV=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
